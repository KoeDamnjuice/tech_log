{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01f7d149-98e7-4bb2-a085-767997fc0ec8",
   "metadata": {},
   "source": [
    "# Tensor是什么\n",
    "torch中的tensor类似numpy的ndarrays, 是最基本的数据结构，用于存储和操作多维数组。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b6cc53-abe1-4d89-bf5c-e578affa3409",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793e2f0e",
   "metadata": {},
   "source": [
    "\n",
    "___\n",
    "\n",
    "### 创建tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38d0068-e29c-4138-ab99-a3c621943b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 列表到张量\n",
    "tensor_from_list = torch.tensor([1,2,30])\n",
    "# ndarray 搭配张量\n",
    "np_array = np.array([4,5,6])\n",
    "tensor_from_numpy = torch.tensor(np_array)\n",
    "print(tensor_from_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be553003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 全零\n",
    "zero_tensor = torch.zeros((3, 4))\n",
    "print(zero_tensor)\n",
    "# 全1\n",
    "ones_tensor = torch.ones((2,2))\n",
    "print(ones_tensor)\n",
    "# 指定范围张量\n",
    "range_tensor = torch.arange(0, 10, 2)\n",
    "print(range_tensor)\n",
    "# 均匀分布的tensor\n",
    "mean_tensor = torch.rand((3,3))\n",
    "print(mean_tensor)\n",
    "# 正态分布tensor\n",
    "normal_tensor = torch.randn((3,3))\n",
    "print(normal_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fc02f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 未初始化的tensor\n",
    "empty_tensor = torch.empty((2,2))\n",
    "\n",
    "# 常见与某个tensor形状相同的tensor\n",
    "same_shape_tensor = torch.ones_like(normal_tensor)\n",
    "print(empty_tensor)\n",
    "print(same_shape_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685f5339",
   "metadata": {},
   "source": [
    "\n",
    "___\n",
    "\n",
    "## 张量的基本操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f4081d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 张量的尺寸\n",
    "# tensor_from_list = torch.tensor([1,2,30])\n",
    "shape_tensor = tensor_from_list.shape\n",
    "print(shape_tensor)\n",
    "\n",
    "# 索引\n",
    "element = tensor_from_list[0]\n",
    "print(element)\n",
    "\n",
    "# 切片\n",
    "sliced_tensor = tensor_from_list[:2]\n",
    "print(sliced_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e34067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 改变张量的形状\n",
    "reshaped_tensor = tensor_from_list.view(1,3)\n",
    "# 改成1，3相当于从一维张量转为了二维张量\n",
    "print(reshaped_tensor)\n",
    "# 张量转置\n",
    "transposed_tensor = tensor_from_list.t()\n",
    "print(transposed_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2809a6",
   "metadata": {},
   "source": [
    "**数学计算**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d432cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_o = torch.ones(1,3)\n",
    "tensor_rand = torch.randn(1,3)\n",
    "print(tensor_o, tensor_rand)\n",
    "\n",
    "#加法操作\n",
    "tensor_sum = tensor_o + tensor_rand\n",
    "print(\"sum:\", tensor_sum)\n",
    "\n",
    "# 乘法操作: 注意matmul是典型的矩阵乘法\n",
    "product_tensor = torch.matmul(tensor_sum, tensor_o.t())\n",
    "print(product_tensor)\n",
    "product_tensor_2 = torch.matmul(tensor_sum.t(), tensor_o)\n",
    "print(product_tensor_2)\n",
    "\n",
    "# 广播计算\n",
    "tensor_o_broad = tensor_o * 3\n",
    "print(tensor_o_broad)\n",
    "tensor_o_broad_2 = tensor_o_broad + 2\n",
    "print(tensor_o_broad_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e4315f",
   "metadata": {},
   "source": [
    "## 自动求导\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3770440",
   "metadata": {},
   "source": [
    "# 自动求导\n",
    "pytorch自动求导的核心是torch.autograd模块，它为对张量的所有操作提供了自动求导服务，其核心部分包含:\n",
    "+ tensor\n",
    "+ 计算图\n",
    "+ 梯度计算\n",
    "+ 梯度累计\n",
    "+ 离散跟踪"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075be503",
   "metadata": {},
   "source": [
    "如果张量的requires_grad属性被设置为True，那么对它的每一步操作都将被跟踪。当结束计算后，可以调用**backward()**方法，来自动计算所有参数的梯度，注意这个梯度是**累加的**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef5f8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(3, 3, requires_grad = True)\n",
    "print(x.grad_fn)\n",
    "# 由于x是用户创建的叶子节点，因此没有跟踪计算图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3089b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones(2,2, requires_grad= True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f247a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对张量进行一次计算\n",
    "y = x ** 2\n",
    "print(y)\n",
    "print(y.grad_fn)\n",
    "# more\n",
    "z = y * y * 3\n",
    "out = z.mean()\n",
    "print(z, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c69ff9",
   "metadata": {},
   "source": [
    "由于y是对x进行操作的结果，因此这个操作会被跟踪，y的grad_fn属性为grad_fn=<PowBackward0>, 字面上看是幂计算反向传播。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bd9702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# requires_grad属性默认是false\n",
    "a = torch.randn(3,2)\n",
    "a = ((a * 3) / (a - 1))\n",
    "print(a.requires_grad)\n",
    "# .requires_grad_()方法可以原地修改张量的requires_grad属性\n",
    "a.requires_grad_(True)\n",
    "b = (a * a).sum()\n",
    "print(b.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3b897b",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## 梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3e564e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对out反向传播\n",
    "out.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78609c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 看看d(out)/dx\n",
    "print(x)\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061cb172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 雅可比向量积的例子:\n",
    "j = torch.randn(3, requires_grad=True)\n",
    "print(j)\n",
    "\n",
    "k = j * 2\n",
    "m = 0\n",
    "while k.data.norm() < 1000:\n",
    "    k = k * 2\n",
    "    m = m + 1\n",
    "print(k)\n",
    "print(m)\n",
    "# 此时k已经不再是标量，autograd不能直接计算梯度，因此只可以求雅可比向量积。\n",
    "v = torch.tensor([0.1, 1.0, 0.0001],dtype=torch.float)\n",
    "k.backward(v)\n",
    "print(j.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659c80a0",
   "metadata": {},
   "source": [
    "注意，auto_grad只能直接求**标量**结果的反向传播结果。如果结果是向量的话，对所有输入求导就会得到一个**雅可比矩阵**，而不是该输入的梯度值。因此，如果最终结果是向量的话，backward()需要引入一个与输出同维度的权重向量。\n",
    "\n",
    "___\n",
    "\n",
    "***梯度的累加机制***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a73a4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果不手动对参数的梯度清零的话，其梯度会一直累加\n",
    "out2 = x.sum()\n",
    "out2.backward()\n",
    "print(x.grad)\n",
    "out3 = x.sum()\n",
    "x.grad.data.zero_()\n",
    "out3.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b859f509",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## 离散追踪\n",
    "推理或者验证模型的时候，我们不希望数值计算过程被追踪，因为那样会消耗额外的内存与算力。此时使用torch.no_grad()来临时将tensor的requires_grad属性设置为False。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c48a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(j.requires_grad)\n",
    "print((j ** 2).requires_grad)\n",
    "\n",
    "with torch.no_grad():\n",
    "    print((j ** 2).requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a91dc0e",
   "metadata": {},
   "source": [
    "___\n",
    "tip:如果我们希望改变一个tensor的值，却不想该百年它的autograd记录，那么就直接对tensor.data属性进行操作："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1a4e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones(1, requires_grad=True)\n",
    "\n",
    "print(x.data)  # 其实还是一个tensor\n",
    "print(x.data.requires_grad)\n",
    "\n",
    "y = 2 * x\n",
    "x.data *= 100 # 只改变了值，不会记录在计算图，所以不会影响梯度传播\n",
    "y.backward()\n",
    "print(x)\n",
    "print(x.grad)  # 发现导数为2， 与100无关"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3309e0",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## grad_fn属性详解\n",
    "\n",
    "当我们对张量进行运算的时候，得到的张量的grad_fn会自动记录该操作，**并指向一个Function对象**，该对象复制前向传播和反向传播。tensor与Function共同组成一个无环有向的计算图。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6993d5dd",
   "metadata": {},
   "source": [
    "# 多gpu并行计算"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3296bd25",
   "metadata": {},
   "source": [
    "### 什么是CUDA?\n",
    "CUDA是英伟达GPU的并行运算框架。对GPU的编程是使用CUDA语言完成的。然而pytorch的cuda意思是我们即将使用GPU来处理数据和模型。\n",
    "\n",
    "当我们希望把模型或者数据从cpu迁移到gpu时，就需要使用.cuda()方法（默认0号gpu）。\n",
    "tips：\n",
    "+ pytorch目前不支持amd的opengl接口\n",
    "+ 避免频繁地将数据在cpu和gpu之间切换\n",
    "+ 进行简单操作时，使用cpu\n",
    "\n",
    "——————\n",
    "\n",
    "如何设置默认显卡？两种方法\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993a2c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    " #设置在文件最开始部分\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICE\"] = \"2\" # 设置默认的显卡\n",
    "# 或者\n",
    "CUDA_VISBLE_DEVICE=0,1 python train.py # 使用0，1两块GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cdc78cb",
   "metadata": {},
   "source": [
    "## 常见的并行训练方法：\n",
    "\n",
    "**1.mambaout,模型拆分**  \n",
    "![模型拆分图解](https://datawhalechina.github.io/thorough-pytorch/_images/model_parllel.png)  \n",
    "该方法难在gpu之间的通信\n",
    "\n",
    "**2.同一层任务分不到不同数据中**\n",
    "这种方法将同一层模型做拆分，不太理解  \n",
    "\n",
    "**3.不同数据拆分到不同设备(数据并行方式, data parallelism)**  \n",
    "![](https://datawhalechina.github.io/thorough-pytorch/_images/data_parllel.png)  \n",
    "该方法的逻辑是将相同的模型复制到各个显卡中，然后将数据切分，让各个显卡训练数据的一部分，最后进行汇总反向传播。这样可以解决通信问题。\n",
    "\n",
    "___\n",
    "\n",
    "\n",
    "### 多卡训练 \n",
    "pytorch提供了data parallel(DP)方式和DistributedDataParallel(DDP)两种多卡训练方式"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a9c48c",
   "metadata": {},
   "source": [
    "***使用CUDA加速训练***  \n",
    "**单卡训练**  \n",
    "非常简单，只要将模型和数据.cuda()就行了  \n",
    "首先要手动指定对程序可见的gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb7d547",
   "metadata": {},
   "source": [
    "**多卡DP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5abc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1,2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c2e3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "model.cuda() # 模型显示转移到CUDA上\n",
    "\n",
    "if torch.cuda.device_count() > 1: # 含有多张GPU的卡\n",
    "\tmodel = nn.DataParallel(model) # 单机多卡DP训练"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eccc04f",
   "metadata": {},
   "source": [
    "DP的抽象过程，数据被分为多个子集后，分别在各个gpu计算梯度，最后把梯度汇总到一个主gpu上进行参数的更新，这样会使得主gpu的工作负担明显大于其他gpu，成为性能瓶颈。此外，DP只适合单机模式。**注意DP是单进程多线程**\n",
    "\n",
    "问题：既然python解释器有GIL锁，为什么限制不了DP的加速？\n",
    "因为pytorch数据运行于gpu上，由CUDA和其他GPU加速库管理，不受python解释器管理。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99cd18b",
   "metadata": {},
   "source": [
    "**多机多卡DDP**  \n",
    "DDP是一种多卡多进程方式，每个进程独立运行在一个gpu上，每个gpu独立更新参数，使用高效的通信机制进行梯度信息同步。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c76e7f",
   "metadata": {},
   "source": [
    "## GIL锁对于DP与DDP的影响？\n",
    "由于模型训练大部分内容是在gpu上运行的，因此对于DP，GIL锁对工作的大部分内容几乎没有影响。\n",
    "但是对于**运行于cpu的数据预处理加载和IO操作，还有数据后处理和日志记录等**，可能成为性能瓶颈。\n",
    "但是对于多进程的DDP，由于各个进程都有独立的python解释器，实现了真正的并行运行，因此不受GIL影响。\n",
    "\n",
    "这对于严重依赖 Python runtime 的 models 而言，比如说包含 RNN 层或大量小组件的 models 而言，这尤为重要。什么是python runtime？？？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611462c7",
   "metadata": {},
   "source": [
    "# 深度学习训练的整体流程\n",
    "+ 数据预处理： 数据格式统一、异常数据清除、数据变换\n",
    "+ 划分训练集、验证集、测试集（可以使用sklearn自带的test_train_split函数）\n",
    "+ 模型选择、损失函数、优化方法\n",
    "+ 超参数设置\n",
    "+ 使用模型拟合训练数据集，在验证集、测试机上评估模型表现\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d39b21",
   "metadata": {},
   "source": [
    "## 包的导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81683703",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11a6bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 显式指定gpu\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0, 1' #指明gpu为01\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available else cpu)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cce447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置一些超参数\n",
    "batch_size = 16\n",
    "\n",
    "lr = 1e-4\n",
    "\n",
    "epoch = 100\n",
    "# 当然我们可以选择把超参数存储在yaml里面"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57de9bf5",
   "metadata": {},
   "source": [
    "## 数据读入\n",
    "+ dataset定义数据格式和数据变形形式\n",
    "+ dataloader以迭代的方式，向模型输入批次数据\n",
    "\n",
    "___\n",
    "\n",
    "## dataset\n",
    "**使用torch自建的dataset ImageFolder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356d94bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以cifar10数据集构建Dataset类的方式\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "# 这里使用了PyTorch自带的ImageFolder类的用于读取按一定结构存储的图片数据（path对应图片存放的目录，目录下包含若干子目录，每个子目录对应属于同一个类的图片）\n",
    "train_data = datasets.ImageFolder(train_path, transfor=data_transform)\n",
    "val_data = datasets.ImageFolder(val_path, transform=data_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3844a97b",
   "metadata": {},
   "source": [
    "**使用自定义的dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4f0bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    # 注意实现Dataset父类\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        image1.jpg, 0\n",
    "        image2.jpg, 1\n",
    "        ......\n",
    "        image9.jpg, 9\n",
    "        \n",
    "        \"\"\"\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        # 数据加载\n",
    "        image = read_image(img_path)\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24283aca",
   "metadata": {},
   "source": [
    "构建完成dataset以后，就可以使用dataloader批次读入数据了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026d5e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, num_workers=4, shuffle=True, drop_last=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size, num_workers=4, shuffle=False)\n",
    "# 参数解析\n",
    "# num_workers, cpu读取数据的进程数\n",
    "# drop_last, 对于最后达不到batch_size数量的样本，是否丢弃？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4383a8e8",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## 模型构建\n",
    "**Module 类**是 torch.nn 模块里提供的一个模型构造类，是所有神经网络模块的基类，我们可以继承它来定义我们想要的模型。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "374e7a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用nn.Module构建多层感知机\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    # 在__init__中构建神经网络\n",
    "    def __init__(self, **kwargs):\n",
    "    # 调用MLP父类Block的构造函数来进行必要的初始化。这样在构造实例时还可以指定其他函数\n",
    "        super(MLP, self).__init__(**kwargs)\n",
    "        self.hidden = nn.Linear(784,256)\n",
    "        self.act = nn.ReLU()\n",
    "        self.output = nn.Linear(256, 10)\n",
    "    \n",
    "    # 定义模型的前向计算\n",
    "    def forward(self, x):\n",
    "        o = self.act(self.hidden(x))\n",
    "        return self.output(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba250603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (hidden): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (act): ReLU()\n",
      "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1897, -0.2245, -0.0114, -0.3305,  0.2267, -0.1157,  0.2367, -0.0760,\n",
       "          0.0160,  0.0921],\n",
       "        [-0.0816, -0.0649,  0.1001, -0.0160,  0.1412, -0.2122, -0.3227, -0.3230,\n",
       "         -0.2738, -0.1120]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 随机设置一个输入\n",
    "x = torch.randn(2, 784) # 第一维是batch\n",
    "net = MLP()\n",
    "print(net)\n",
    "net(x)  # 前向计算"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00db050",
   "metadata": {},
   "source": [
    "### 深度学习有各种各样的层, 本节学习使用torch构建自定义层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96de4406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 不含参数的层\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class MyLayer(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MyLayer, self).__init__(**kwargs)\n",
    "    def forward(self, x):\n",
    "        return x - x.mean()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82aeaee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyListDense(\n",
      "  (params): ParameterList(\n",
      "      (0): Parameter containing: [torch.float32 of size 4x4]\n",
      "      (1): Parameter containing: [torch.float32 of size 4x4]\n",
      "      (2): Parameter containing: [torch.float32 of size 4x4]\n",
      "      (3): Parameter containing: [torch.float32 of size 4x1]\n",
      "  )\n",
      ")\n",
      "MyDictDense(\n",
      "  (params): ParameterDict(\n",
      "      (linear1): Parameter containing: [torch.FloatTensor of size 4x4]\n",
      "      (linear2): Parameter containing: [torch.FloatTensor of size 4x1]\n",
      "      (linear3): Parameter containing: [torch.FloatTensor of size 4x2]\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 自定义参数的层，注意Parameter是Tensor的子类型，会被自动添加到模型的参数列表之中,使之可以训练\n",
    "# 这样的话，似乎就可以实现模型手撕了\n",
    "class MyListDense(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyListDense, self).__init__()\n",
    "        self.params = nn.ParameterList([nn.Parameter(torch.randn(4, 4)) for i in range(3)])\n",
    "        self.params.append(nn.Parameter(torch.randn(4, 1)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i in range(len(self.params)):\n",
    "            # mm，仅仅可以对付二维矩阵乘法\n",
    "            x = torch.mm(x, self.params[i])\n",
    "        return x\n",
    "net = MyListDense()\n",
    "print(net)\n",
    "\n",
    "class MyDictDense(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyDictDense, self).__init__()\n",
    "        self.params = nn.ParameterDict({\n",
    "                'linear1': nn.Parameter(torch.randn(4, 4)),\n",
    "                'linear2': nn.Parameter(torch.randn(4, 1))\n",
    "        })\n",
    "        self.params.update({'linear3': nn.Parameter(torch.randn(4, 2))}) # 新增\n",
    "\n",
    "    def forward(self, x, choice='linear1'):\n",
    "        return torch.mm(x, self.params[choice])\n",
    "\n",
    "net = MyDictDense()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360a1002",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "### 卷积层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eaae9455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 手撕二维卷积！！！\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "def corr2d(X, K):\n",
    "    h, w = K.shape\n",
    "    print(h,w)\n",
    "    X, K = X.float(), K.float()\n",
    "    Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i, j] = (X[i: i + h, j: j + w] * K).sum()\n",
    "    return Y\n",
    "\n",
    "class Conv2D(nn.Module):\n",
    "    def __init__(self, kernel_size):\n",
    "        super(Conv2D, self).__init()\n",
    "        # super 方法用于为子类调用父类方法，type参数\n",
    "        # 传入类型， obj传入实例，在类定义中, obj传入\n",
    "        # self\n",
    "        self.weight = nn.Parameter(torch.randn(kernel_size))\n",
    "        self.bias = nn.Parameter(torch.randn(1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return corr2d(x, self.weight) + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "487c328a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "# 使用padding进行same卷积\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "def comp_conv2d(conv2d, X):\n",
    "    X = X.view((1,1) + X.shape) # 为X加入批次和通道维度\n",
    "    Y = conv2d(X)\n",
    "    return Y.view(Y.shape[2:]) # 滤除批次和通道维度\n",
    "\n",
    "# 对输入左右padding两行\n",
    "conv2d = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=3, padding= 1)\n",
    "\n",
    "X = torch.rand(8,8)\n",
    "# 注意卷积之后前后变换公式: y = (x - h + 2 * p)/s + 1, 注意向下取整\n",
    "print(comp_conv2d(conv2d, X).shape)\n",
    "\n",
    "# 使用高宽不一致的卷积核\n",
    "conv2d = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=(5, 3), padding=(2, 1))\n",
    "print(comp_conv2d(conv2d, X).shape)\n",
    "\n",
    "# 引入stride\n",
    "conv2d = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=(3, 5), padding= (0, 1), stride = (3, 4))\n",
    "print(comp_conv2d(conv2d, X).shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5e3ba8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5., 6.],\n",
      "        [8., 9.]])\n",
      "tensor([[2.5000, 3.5000],\n",
      "        [6.0000, 7.0000]])\n"
     ]
    }
   ],
   "source": [
    "# 手撕池化层\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "def pool2d(X, pool_size, mode = 'max'):\n",
    "    p_h, p_w = pool_size\n",
    "    Y = torch.zeros((X.shape[0] - p_h + 1, X.shape[1] - p_w + 1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            if mode == 'max':\n",
    "                Y[i, j] = X[i: i + p_h, j: j + p_w].max()\n",
    "            elif mode == 'avg':\n",
    "                Y[i, j] = X[i: i + p_h, j: j + p_w].mean()\n",
    "    return Y\n",
    "\n",
    "X = torch.tensor([[0,1,2],[4,5,6],[7,8,9]], dtype = torch.float)\n",
    "print(pool2d(X, (2,2)))\n",
    "print(pool2d(X,(2,2), \"avg\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fe0017",
   "metadata": {},
   "source": [
    "### 关于U-NET中上采样或者解码层的一些补充\n",
    "上采样的两种方法：\n",
    "+ 双线性插值上采样(无需学习): 使用插值的方法增加像素点，通过双线性插值可以得到平滑输出但是\n",
    "失去高频细节\n",
    "+ 转置卷积(需要学习)\n",
    "\n",
    "**转置卷积的实现：**首先是输入扩展，在每个元素周围插入stride-1个0，然后使用常规的卷积方式进行卷积。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14c7d35",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "# 模型初始化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50aa4df6",
   "metadata": {},
   "source": [
    "### 为什么参数初始化不能全部为0  \n",
    "当网络中所有权重都初始化为0时，对于任何隐藏层，所有神经元在前向传播和反向传播过程中的行为都会完全相同。这意味着每一层的每个神经元将计算出相同的输出，并且在反向传播中也会接收到相同的梯度。结果是，即使网络的参数被更新，每个权重也会保持相同，这使得隐藏层的多个神经元没有区分开来，因此无法学习到多样化的特征或模式。  \n",
    "此外，对于一些过零的激活函数（如Sigmoid或Tanh），全部初始化为0也会导致梯度消失问题，当激活函数的输入接近0的时候，其反向传播获得的梯度也会接近0。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87e80c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "**nn.init中提供了一些初始化的方法，这里直接复制**\n",
    " 1 . torch.nn.init.uniform_(tensor, a=0.0, b=1.0)   \n",
    " 2 . torch.nn.init.normal_(tensor, mean=0.0, std=1.0)   \n",
    " 3 . torch.nn.init.constant_(tensor, val)   \n",
    " 4 . torch.nn.init.ones_(tensor)   \n",
    " 5 . torch.nn.init.zeros_(tensor)   \n",
    " 6 . torch.nn.init.eye_(tensor)   \n",
    " 7 . torch.nn.init.dirac_(tensor, groups=1)   \n",
    " 8 . torch.nn.init.xavier_uniform_(tensor, gain=1.0)   \n",
    " 9 . torch.nn.init.xavier_normal_(tensor, gain=1.0)   \n",
    " 10 . torch.nn.init.kaiming_uniform_(tensor, a=0, mode='fan__in', nonlinearity='leaky_relu')   \n",
    " 11 . torch.nn.init.kaiming_normal_(tensor, a=0, mode='fan_in', nonlinearity='leaky_relu')   \n",
    " 12 . torch.nn.init.orthogonal_(tensor, gain=1)   \n",
    " 13 . torch.nn.init.sparse_(tensor, sparsity, std=0.01)   \n",
    " 14 . torch.nn.init.calculate_gain(nonlinearity,  \n",
    " 方法带有下划线，意味着这些方法能原地改变张量的值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f046390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# isinstance方法可以判定某个实例是不是属于某个类型\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "conv = nn.Conv2d(1,3,3)\n",
    "linear = nn.Linear(10,1)\n",
    "\n",
    "\n",
    "print(isinstance(conv, nn.Conv2d))\n",
    "print(isinstance(linear, nn.Conv2d))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6edda7",
   "metadata": {},
   "source": [
    "# 查看一波层的参数\n",
    "print(conv.weight.data)\n",
    "# 3*3的卷积核，输出通道为3，似乎创建出来就被自动初始化了\n",
    "print(linear.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b43a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对conv进行kaiming初始化\n",
    "torch.nn.init.kaiming_normal_(conv.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e65f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对linear进行常数初始化\n",
    "torch.nn.init.constant_(linear.weight.data,0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbbc653",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "# 损失函数\n",
    "损失函数衡量了预测信息与标签信息之间的差距，用于为模型训练提供负反馈，是反向传播的起点。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b572463",
   "metadata": {},
   "source": [
    "\n",
    "___\n",
    "\n",
    "### PMSQE损失：基于感知指标的语言质量评估\n",
    "传统的均方误差损失MSE只考虑预测语音与目标语音之间的功率谱之间的均方误差，仅仅在数学上缩小了二者功率谱的差异，没有考虑人耳对声音的感知特性，因此基于MSE训练出来的模型在听觉上往往不如人意。\n",
    "PMSQE在MSE的基础上，增添了两个感知扰动项：对称扰动与非对称扰动。它们是基于PESQ简化而来，其中对称扰动衡量了预测语音与目标语音之间的响度差异;非对称扰动是对对称扰动进行加权得到的，加权的值取决于对称扰动的正负，因为人耳对音量增大的敏感度高于对音量减小的敏感度，正差异会获得更大损失。\n",
    "最终MSE、对称扰动、非对称扰动共同构成了PMSQE损失。\n",
    "\n",
    "___\n",
    "### 基于pase编码器的损失：\n",
    "PASE是一个使用子监督方法训练得到的语音特征提取器，其提取出来的语音特征被证明比传统的MFCC谱更有更好性能。基于PASE模型得到音频的embedding，计算预测语音与目标语音embedding之间的MSE。\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab52be2",
   "metadata": {},
   "source": [
    "# 优化器\n",
    "优化器是根据网络反向传播的梯度信息来**更新网络的参数**，以起到降低loss函数计算值，使得模型输出更加接近真实标签。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eaec480",
   "metadata": {},
   "source": [
    "**torch提供了一个优化器库torch.optim**提供多种优化器\n",
    "torch.optim.SGD\n",
    "\n",
    "torch.optim.ASGD\n",
    "\n",
    "torch.optim.Adadelta\n",
    "\n",
    "torch.optim.Adagrad\n",
    "\n",
    "torch.optim.Adam\n",
    "...\n",
    "这些优化器都继承自基类**Optimizer**,定义:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d1e7414",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer(object):\n",
    "    def __init__(self, params, defaults):        \n",
    "        self.defaults = defaults # 存储一些通用超参数，比如momentum的beta，rmsprop的beta\n",
    "        self.state = defaultdict(dict) # 优化器状态参数缓存，比如累加的梯度\n",
    "        self.param_groups = [] # 字典列表，每个元素是个字典，包含需要训练的parameter，对应的学习率，权重衰减\n",
    "\n",
    "    # 介绍Optimizer的一些方法\n",
    "    # 清空梯度缓存\n",
    "    def zero_grad(self, set_to_none: bool = False):\n",
    "        for group in self.param_groups:\n",
    "            for p in group['params']:\n",
    "                if p.grad is not None:  #梯度不为空\n",
    "                    if set_to_none: \n",
    "                        p.grad = None\n",
    "                    else:\n",
    "                        if p.grad.grad_fn is not None:\n",
    "                            p.grad.detach_()  # 断开计算图\n",
    "                        else:\n",
    "                            p.grad.requires_grad_(False)\n",
    "                        p.grad.zero_()# 梯度设置为0\n",
    "\n",
    "    # 执行参数更新\n",
    "    def step(self, closure): \n",
    "        raise NotImplementedError\n",
    "\n",
    "    # 添加参数组\n",
    "    def add_param_group(self, param_group):\n",
    "        pass\n",
    "\n",
    "    # 加载状态参数字典，用于断点续训练\n",
    "    def load_state_dict(self, state_dict):\n",
    "        ...\n",
    "\n",
    "    def cast(param, value):\n",
    "        ...\n",
    "\n",
    "    # Update parameter groups, setting their 'params' value\n",
    "    def update_group(group, new_group):\n",
    "       ...\n",
    "       \n",
    "    # 获取当前优化器状态信息字典\n",
    "    def state_dict(self):\n",
    "        ...\n",
    "\n",
    "    def pack_group(group):\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70072e16",
   "metadata": {},
   "source": [
    "\n",
    "### 随机梯度下降法SGD\n",
    "在torch中，欲实现SGD，需要设置batch_size为1。即计算一个样本的损失，就更新参数。\n",
    "+ 缺陷：噪声与抖动非常大，而且永远无法收敛至最小值。\n",
    "\n",
    "### mini-batch梯度下降法\n",
    "将m个样本拼接成一个batch，累加m个样本的梯度求平均，然后更新参数，噪声相对于SGD小。当然性能消耗也会大于SGD。\n",
    "\n",
    "### batch梯度下降法\n",
    "将所有样本一次性输入，累加梯度后求平均，噪声非常小，但数据量巨大，在现代深度学习任务中几乎不可能实现。\n",
    "\n",
    "## 知识点：指数加权平均\n",
    "指数加权平均是一种计算机易实现的数据平滑处理。\n",
    "$v_t = \\beta v_{t-1} + (1 - \\beta)\\theta_t$  \n",
    "v和theta分别代表了平滑值与瞬时值。平滑窗口长度约为$\\frac{1}{1 - \\beta}$\n",
    "\n",
    "### momentum动量梯度下降法：\n",
    "momentum的核心在于指数加权平均，在梯度下降过程中，正负摆动会被平滑掉，而朝着损失下降的方向由于固定，不会被平滑。在momentum梯度下降法中，超参数包含$\\beta$与$\\alpha$，分别是指数加权平均的参数和学习率。\n",
    "\n",
    "### RMSprop梯度下降算法：\n",
    "不同于momentum仅仅平滑了梯度，RMSprop还对参数变化进行了加速。\n",
    "$$S_{dw} = \\beta S_{dw} + (1 - \\beta)dW^2$$\n",
    "$$S_{db} = \\beta S_{db} + (1 - \\beta)db^2$$\n",
    "$$W = W - \\alpha \\frac{dW}{\\sqrt{S_{dW}}}$$\n",
    "$$W = b - \\alpha \\frac{db}{\\sqrt{S_{db}}}$$  \n",
    "\n",
    "对于变化比较剧烈的参数，S会比较大，更新时会收到抑制，变化微弱的参数，更新时会得到放大。\n",
    "\n",
    "### Adam优化算法\n",
    "adam融合了momentum算法和RMSprop算法，既对梯度进行了平滑，又对参数更新进行了加速。因此同时拥有了动量梯度下降的$\\beta1$，又有了RMSprop算法$\\beta2$\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a45f22",
   "metadata": {},
   "source": [
    "## torch优化器实际操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75f54d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data of weight before step:\n",
      "tensor([[-0.5980, -2.6022],\n",
      "        [-0.2394,  0.7446]])\n",
      "The grad of weight before step:\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "# 初始化权重\n",
    "weight = torch.randn((2,2), requires_grad=True)\n",
    "# 设置梯度为全1矩阵 --> 2 * 2\n",
    "weight.grad = torch.ones((2,2))\n",
    "print(\"The data of weight before step:\\n{}\".format(weight.data))\n",
    "print(\"The grad of weight before step:\\n{}\".format(weight.grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cbae2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data of weight after step:\n",
      "tensor([[-0.6980, -2.7022],\n",
      "        [-0.3394,  0.6446]])\n",
      "The grad of weight after step:\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# 实例化优化器\n",
    "optimizer = torch.optim.SGD([weight], lr=0.1, momentum=0.9)\n",
    "# 更新下参数\n",
    "optimizer.step()\n",
    "print(\"The data of weight after step:\\n{}\".format(weight.data))\n",
    "print(\"The grad of weight after step:\\n{}\".format(weight.grad))\n",
    "# 发现参数都降低了0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfc7bc00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The grad of weight after optimizer.zero_grad():\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 梯度清零\n",
    "optimizer.zero_grad()\n",
    "print(\"The grad of weight after optimizer.zero_grad():\\n{}\".format(weight.grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd7092ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimizer.params_group is \n",
      "[{'params': [tensor([[-0.6980, -2.7022],\n",
      "        [-0.3394,  0.6446]], requires_grad=True)], 'lr': 0.1, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'maximize': False, 'foreach': None, 'differentiable': False, 'fused': None}]\n",
      "weight in optimizer:140464894949392\n",
      "weight in weight:140464894949392\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"optimizer.params_group is \\n{}\".format(optimizer.param_groups))\n",
    "print(\"weight in optimizer:{}\\nweight in weight:{}\\n\".format(id(optimizer.param_groups[0]['params'][0]), id(weight)))\n",
    "# 上面发现optimizer.param_groups[0][\"params\"[0]]和weight指向同一个对象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95c23d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimizer.param_groups is\n",
      "[{'params': [tensor([[-0.6980, -2.7022],\n",
      "        [-0.3394,  0.6446]], requires_grad=True)], 'lr': 0.1, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'maximize': False, 'foreach': None, 'differentiable': False, 'fused': None}, {'params': [tensor([[0.4579, 0.4673, 0.5956],\n",
      "        [0.7286, 0.6144, 0.7743],\n",
      "        [0.4208, 0.2964, 0.2083]], requires_grad=True)], 'lr': 0.0001, 'nesterov': True, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'maximize': False, 'foreach': None, 'differentiable': False, 'fused': None}]\n"
     ]
    }
   ],
   "source": [
    "# 添加参数：weight2\n",
    "weight = torch.rand((3,3 ), requires_grad= True)\n",
    "optimizer.add_param_group({\"params\": weight, \"lr\" :0.0001, \"nesterov\": True})\n",
    "# 查\n",
    "print(\"optimizer.param_groups is\\n{}\".format(optimizer.param_groups))\n",
    "# 发现default属性的确存储的是统一超参数，但优先级低于param_group中的超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a14eb5fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state_dict before step:\n",
      " {'state': {0: {'momentum_buffer': tensor([[1., 1.],\n",
      "        [1., 1.]])}}, 'param_groups': [{'lr': 0.1, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'maximize': False, 'foreach': None, 'differentiable': False, 'fused': None, 'params': [0]}, {'lr': 0.0001, 'nesterov': True, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'maximize': False, 'foreach': None, 'differentiable': False, 'fused': None, 'params': [1]}]}\n"
     ]
    }
   ],
   "source": [
    "# 查看优化器当前状态信息\n",
    "opt_state_dict = optimizer.state_dict()\n",
    "print(\"state_dict before step:\\n\", opt_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2277d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state_dict after step:\n",
      " {'state': {0: {'momentum_buffer': tensor([[1., 1.],\n",
      "        [1., 1.]])}}, 'param_groups': [{'lr': 0.1, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'maximize': False, 'foreach': None, 'differentiable': False, 'fused': None, 'params': [0]}, {'lr': 0.0001, 'nesterov': True, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'maximize': False, 'foreach': None, 'differentiable': False, 'fused': None, 'params': [1]}]}\n"
     ]
    }
   ],
   "source": [
    "# 50次step\n",
    "for _ in range(50):\n",
    "    optimizer.step()\n",
    "print(\"state_dict after step:\\n\", optimizer.state_dict())\n",
    "# 注意state中只存储一些当前的超参数、梯度等信息，并不存储data\n",
    "# 保存参数信息\n",
    "torch.save(optimizer.state_dict(),os.path.join(r\"D:\\pythonProject\\Attention_Unet\", \"optimizer_state_dict.pkl\"))\n",
    "print(\"----------done-----------\")\n",
    "# 加载参数信息\n",
    "state_dict = torch.load(r\"D:\\pythonProject\\Attention_Unet\\optimizer_state_dict.pkl\") # 需要修改为你自己的路径\n",
    "optimizer.load_state_dict(state_dict)\n",
    "print(\"load state_dict successfully\\n{}\".format(state_dict))\n",
    "# 输出最后属性信息\n",
    "print(\"\\n{}\".format(optimizer.defaults))\n",
    "print(\"\\n{}\".format(optimizer.state))\n",
    "print(\"\\n{}\".format(optimizer.param_groups))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7161328f",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "# 模型定义\n",
    "nn.Module是torch中所有网络模块的基类型。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f16de21",
   "metadata": {},
   "source": [
    "\n",
    "### 使用Sequential类来定义串联层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b24f6d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 直接法\n",
    "import torch.nn as nn\n",
    "net = nn.Sequential(\n",
    "    nn.Linear(784, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256,10)\n",
    ")\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01b2b66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (fc1): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (relu1): ReLU()\n",
      "  (fc2): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 使用OrderedDict\n",
    "import collections\n",
    "import torch.nn as nn\n",
    "net2 = nn.Sequential(collections.OrderedDict([\n",
    "          ('fc1', nn.Linear(784, 256)),\n",
    "          ('relu1', nn.ReLU()),\n",
    "          ('fc2', nn.Linear(256, 10))\n",
    "          ]))\n",
    "print(net2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd808de4",
   "metadata": {},
   "source": [
    "### 模型列表ModuleList\n",
    "接受子模块作为输入，可以类似list那样append和extend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54ac56e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=256, out_features=10, bias=True)\n",
      "ModuleList(\n",
      "  (0): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = nn.ModuleList([nn.Linear(784,256), nn.ReLU()])\n",
    "net.append(nn.Linear(256,10))\n",
    "print(net[-1])\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf7f4ae",
   "metadata": {},
   "source": [
    "**注意modulelist不能像sequential那样直接forward，而应该遍历列表的层分别forward**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6631493",
   "metadata": {},
   "source": [
    "# 修改现有模型\n",
    "开源模型越来越多，我们没必要手动去搓模型了。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5967bae7",
   "metadata": {},
   "source": [
    "### 篡改resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e9ea058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "import torchvision.models as models\n",
    "net = models.resnet50()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146978c4",
   "metadata": {},
   "source": [
    "如果我们希望修改model，进行十分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9b26b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Sequential(\n",
      "    (fc1): Linear(in_features=2048, out_features=128, bias=True)\n",
      "    (relu1): ReLU()\n",
      "    (dropout1): Dropout(p=0.5, inplace=False)\n",
      "    (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      "    (output): Softmax(dim=1)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 我们把最终的fc层修改为含有两个隐藏层的全链接层\n",
    "classifier = nn.Sequential(OrderedDict([\n",
    "    (\"fc1\", nn.Linear(2048, 128)),\n",
    "    ('relu1', nn.ReLU()), \n",
    "    ('dropout1',nn.Dropout(0.5)),\n",
    "    ('fc2', nn.Linear(128, 10)),\n",
    "    ('output', nn.Softmax(dim=1))\n",
    "]))\n",
    "net.fc = classifier\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f64cc5e",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "# torch中模型的输出&存储\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbe4303",
   "metadata": {},
   "source": [
    "torch的模型一般以pkl,pt或者pth三种格式存储.pt和pth必须有pytorch环境的支持,pkl更加通用而不安全.  \n",
    "pt和pth本质上是一样的,用于存储pytorch的模型和张量.  \n",
    "pkl是python的通用数据序列化格式,由python的pickle模块实现,可以序列化几乎所有python对象."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ffb180",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "model = models.resnet152(pretrained=True)\n",
    "save_dir = './resnet152.pth'\n",
    "\n",
    "# 保存整个模型\n",
    "torch.save(model, save_dir)\n",
    "# 保存模型权重\n",
    "torch.save(model.state_dict, save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27191d5",
   "metadata": {},
   "source": [
    "# 动态调整学习率\n",
    "学习率过小会造成学习缓慢，过大会导致损失震荡，因此，我们需要动态调整学习率，训练初期我们希望训练更加快速，因此学习率较大，后期为了防止损失震荡，会降低学习率。在pytorch中，可以设置一个学习率衰减策略来动态调整学习率，这个工具叫做调度器scheduler。\n",
    "在torch.optim.lr_scheduler模块中封装好了一系列调度器：\n",
    "lr_scheduler.LambdaLR\n",
    "\n",
    "lr_scheduler.MultiplicativeLR\n",
    "\n",
    "lr_scheduler.StepLR\n",
    "\n",
    "lr_scheduler.MultiStepLR\n",
    "\n",
    "lr_scheduler.ExponentialLR\n",
    "\n",
    "lr_scheduler.CosineAnnealingLR\n",
    "\n",
    "lr_scheduler.ReduceLROnPlateau\n",
    "\n",
    "lr_scheduler.CyclicLR\n",
    "\n",
    "lr_scheduler.OneCycleLR\n",
    "\n",
    "lr_scheduler.CosineAnnealingWarmRestarts\n",
    "\n",
    "lr_scheduler.ConstantLR\n",
    "\n",
    "lr_scheduler.LinearLR\n",
    "\n",
    "lr_scheduler.PolynomialLR\n",
    "\n",
    "lr_scheduler.ChainedScheduler\n",
    "\n",
    "lr_scheduler.SequentialLR\n",
    "\n",
    "他们都继承自_LRScheduler类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6670298e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学习率调度往往是在训练完一个epoch后执行的：\n",
    "# 选择一种优化器\n",
    "optimizer = torch.optim.Adam(...) \n",
    "# 选择上面提到的一种或多种动态调整学习率的方法\n",
    "scheduler1 = torch.optim.lr_scheduler.... \n",
    "scheduler2 = torch.optim.lr_scheduler....\n",
    "...\n",
    "schedulern = torch.optim.lr_scheduler....\n",
    "# 进行训练\n",
    "for epoch in range(100):\n",
    "    train(...)\n",
    "    validate(...)\n",
    "    optimizer.step()\n",
    "    # 需要在优化器参数更新之后再动态调整学习率\n",
    "# scheduler的优化是在每一轮后面进行的\n",
    "scheduler1.step() \n",
    "...\n",
    "schedulern.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c98460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在之前的内容中我们知道训练的权重、梯度、学习率等内容都存储在optimizer的param_group中\n",
    "# 因此如果希望自定义一个scheduler，我们的核心就是修改param_group的\"lr\"\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    lr = args.lr * (0.1 ** (epoch // 30))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr = args.lr,momentum = 0.9)\n",
    "for epoch in range(10):\n",
    "    train(...)\n",
    "    validate(...)\n",
    "    adjust_learning_rate(optimizer,epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9398b1d",
   "metadata": {},
   "source": [
    "# 深度学习模型微调\n",
    "实际任务中，我们手上的数据很少，几乎不可能直接从头训练一个模型，因为可能会导致过拟合。因此借用别人的预训练模型来进行微调显得非常重要。\n",
    "在pytorch中提供了非常多的预训练模型，比如VGG、Resnet等等。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5995df3d",
   "metadata": {},
   "source": [
    "### 微调的基本流程\n",
    "+ 在开源大量的源数据集上训练一个源模型\n",
    "+ 替换源数据集的输出层，使之适应新数据集的任务\n",
    "+ 在目标数据集上，从头训练输出层，并微调其他层。  \n",
    "![微调流程](https://datawhalechina.github.io/thorough-pytorch/_images/finetune.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3412c071",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda\\envs\\project\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "d:\\miniconda\\envs\\project\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "d:\\miniconda\\envs\\project\\lib\\site-packages\\torchvision\\models\\inception.py:43: FutureWarning: The default weight initialization of inception_v3 will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.\n",
      "  warnings.warn(\n",
      "d:\\miniconda\\envs\\project\\lib\\site-packages\\torchvision\\models\\googlenet.py:47: FutureWarning: The default weight initialization of GoogleNet will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 首先，从torchvision库搞个预训练模型下来\n",
    "# 默认情况下，models中的模型是不包含预训练参数的\n",
    "import torchvision.models as models\n",
    "resnet18 = models.resnet18(pretrained=False)\n",
    "alexnet = models.alexnet()\n",
    "vgg16 = models.vgg16()\n",
    "squeezenet = models.squeezenet1_0()\n",
    "densenet = models.densenet161()\n",
    "inception = models.inception_v3()\n",
    "googlenet = models.googlenet()\n",
    "shufflenet = models.shufflenet_v2_x1_0()\n",
    "mobilenet_v2 = models.mobilenet_v2()\n",
    "mobilenet_v3_large = models.mobilenet_v3_large()\n",
    "mobilenet_v3_small = models.mobilenet_v3_small()\n",
    "resnext50_32x4d = models.resnext50_32x4d()\n",
    "wide_resnet50_2 = models.wide_resnet50_2()\n",
    "mnasnet = models.mnasnet1_0()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d370ff0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 因此需要显式地指明使用预训练参数\n",
    "resnet18 = models.resnet18(pretrained=True)\n",
    "# 如果出现下载不成功的话，可以手动下载权重，使用model.load_state_dicet方法来装载参数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3005a6e4",
   "metadata": {},
   "source": [
    "### 训练模型的特定层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e3dca7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda\\envs\\project\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "d:\\miniconda\\envs\\project\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# 首先冻结所有参数的梯度计算\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "\n",
    "def set_param_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "feature_extract = True\n",
    "model = models.resnet18(pretrained = True)\n",
    "set_param_requires_grad(model, feature_extract)\n",
    "\n",
    "# 自定义一个输出的全连接层\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(in_features = num_ftrs, out_features=4, bias=True)\n",
    "\n",
    "#之后在训练过程中，model仍会进行梯度回传，但是参数更新则只会发生在fc层。\n",
    "#通过设定参数的requires_grad属性，我们完成了指定训练模型的特定层的目标，这对实现模型微调非常重要。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd52b629",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "# 半精度训练\n",
    "在pytorch中训练模型的过程中，默认的数据存储方式为torch.flat32, 这会使得计算精度更高，同时也导致了更大的算力和显存需求。  \n",
    "因此在一些不要求那么精准的训练中，可以采样***半精度***训练，保留一半的数据长度，即使用float16。  \n",
    "在torch中，我们使用autocast类来进行半精度配置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "441a5efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.cuda.amp import autocast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249775ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在模型定义中，我们可以指定forward为半精度，使用autocast装饰。\n",
    "@autocast()\n",
    "def forward(self,x):\n",
    "    ...\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9131f31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在训练过程中，也可以在数据输入模型之前加入with autocast()上下文就可以了\n",
    "for x in train_loader:\n",
    "    x = x.cuda()\n",
    "    with autocast():\n",
    "        output = model(x)\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0264964",
   "metadata": {},
   "source": [
    "# 特别学习：torchaudio，联想librosa、 soundfile\n",
    "torchaudio.io：有关音频的I/O\n",
    "\n",
    "torchaudio.backend：提供了音频处理的后端，包括：sox，soundfile等\n",
    "\n",
    "torchaudio.functional：包含了常用的语音数据处理方法，如：spectrogram，create_fb_matrix等\n",
    "\n",
    "torchaudio.transforms：包含了常用的语音数据预处理方法，如：MFCC，MelScale，AmplitudeToDB等\n",
    "\n",
    "torchaudio.datasets：包含了常用的语音数据集，如：VCTK，LibriSpeech，yesno等\n",
    "\n",
    "torchaudio.models：包含了常用的语音模型，如：Wav2Letter，DeepSpeech等\n",
    "\n",
    "torchaudio.models.decoder：包含了常用的语音解码器，如：GreedyDecoder，BeamSearchDecoder等\n",
    "\n",
    "torchaudio.pipelines：包含了常用的语音处理流水线，如：SpeechRecognitionPipeline，SpeakerRecognitionPipeline等\n",
    "\n",
    "torchaudio.sox_effects：包含了常用的语音处理方法，如：apply_effects_tensor，apply_effects_file等\n",
    "\n",
    "torchaudio.compliance.kaldi：包含了与Kaldi工具兼容的方法，如：load_kaldi_fst，load_kaldi_ark等\n",
    "\n",
    "torchaudio.kalid_io：包含了与Kaldi工具兼容的方法，如：read_vec_flt_scp，read_vec_int_scp等\n",
    "\n",
    "torchaudio.utils：包含了常用的语音工具方法，如：get_audio_backend，set_audio_backend等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11fffbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 直接使用torchaudio自带的YESNO数据集构建dataset\n",
    "import torchaudio\n",
    "import torch\n",
    "\n",
    "yesno_data = torchaudio.datasets.YESNO('.', download=True)\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    yesno_data,\n",
    "    batch_size=1,\n",
    "    shuffle=True,\n",
    "    num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c87c0cac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CMUARCTIC',\n",
       " 'CMUDict',\n",
       " 'COMMONVOICE',\n",
       " 'DR_VCTK',\n",
       " 'FluentSpeechCommands',\n",
       " 'GTZAN',\n",
       " 'IEMOCAP',\n",
       " 'LIBRISPEECH',\n",
       " 'LIBRITTS',\n",
       " 'LJSPEECH',\n",
       " 'LibriLightLimited',\n",
       " 'LibriMix',\n",
       " 'LibriSpeechBiasing',\n",
       " 'MUSDB_HQ',\n",
       " 'QUESST14',\n",
       " 'SPEECHCOMMANDS',\n",
       " 'Snips',\n",
       " 'TEDLIUM',\n",
       " 'VCTK_092',\n",
       " 'VoxCeleb1Identification',\n",
       " 'VoxCeleb1Verification',\n",
       " 'YESNO',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " 'cmuarctic',\n",
       " 'cmudict',\n",
       " 'commonvoice',\n",
       " 'dr_vctk',\n",
       " 'fluentcommands',\n",
       " 'gtzan',\n",
       " 'iemocap',\n",
       " 'librilight_limited',\n",
       " 'librimix',\n",
       " 'librispeech',\n",
       " 'librispeech_biasing',\n",
       " 'libritts',\n",
       " 'ljspeech',\n",
       " 'musdb_hq',\n",
       " 'quesst14',\n",
       " 'snips',\n",
       " 'speechcommands',\n",
       " 'tedlium',\n",
       " 'utils',\n",
       " 'vctk',\n",
       " 'voxceleb1',\n",
       " 'yesno']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torchaudio自带了许多数据集\n",
    "import torchaudio\n",
    "\n",
    "dir(torchaudio.datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9393c76e",
   "metadata": {},
   "source": [
    "### torchaudio的transforms\n",
    "类似于torchvision的transforms继承于torch.nn.Module。下图为其方法图解，包含了一系列从频域到其他域的转变方法。  \n",
    "![transforms包](https://datawhalechina.github.io/thorough-pytorch/_images/torchaudio_feature_extractions.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
