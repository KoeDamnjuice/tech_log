{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01f7d149-98e7-4bb2-a085-767997fc0ec8",
   "metadata": {},
   "source": [
    "# Tensor是什么\n",
    "torch中的tensor类似numpy的ndarrays, 是最基本的数据结构，用于存储和操作多维数组。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b6cc53-abe1-4d89-bf5c-e578affa3409",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793e2f0e",
   "metadata": {},
   "source": [
    "\n",
    "___\n",
    "\n",
    "### 创建tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38d0068-e29c-4138-ab99-a3c621943b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 列表到张量\n",
    "tensor_from_list = torch.tensor([1,2,30])\n",
    "# ndarray 搭配张量\n",
    "np_array = np.array([4,5,6])\n",
    "tensor_from_numpy = torch.tensor(np_array)\n",
    "print(tensor_from_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be553003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 全零\n",
    "zero_tensor = torch.zeros((3, 4))\n",
    "print(zero_tensor)\n",
    "# 全1\n",
    "ones_tensor = torch.ones((2,2))\n",
    "print(ones_tensor)\n",
    "# 指定范围张量\n",
    "range_tensor = torch.arange(0, 10, 2)\n",
    "print(range_tensor)\n",
    "# 均匀分布的tensor\n",
    "mean_tensor = torch.rand((3,3))\n",
    "print(mean_tensor)\n",
    "# 正态分布tensor\n",
    "normal_tensor = torch.randn((3,3))\n",
    "print(normal_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fc02f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 未初始化的tensor\n",
    "empty_tensor = torch.empty((2,2))\n",
    "\n",
    "# 常见与某个tensor形状相同的tensor\n",
    "same_shape_tensor = torch.ones_like(normal_tensor)\n",
    "print(empty_tensor)\n",
    "print(same_shape_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685f5339",
   "metadata": {},
   "source": [
    "\n",
    "___\n",
    "\n",
    "## 张量的基本操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f4081d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 张量的尺寸\n",
    "# tensor_from_list = torch.tensor([1,2,30])\n",
    "shape_tensor = tensor_from_list.shape\n",
    "print(shape_tensor)\n",
    "\n",
    "# 索引\n",
    "element = tensor_from_list[0]\n",
    "print(element)\n",
    "\n",
    "# 切片\n",
    "sliced_tensor = tensor_from_list[:2]\n",
    "print(sliced_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e34067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 改变张量的形状\n",
    "reshaped_tensor = tensor_from_list.view(1,3)\n",
    "# 改成1，3相当于从一维张量转为了二维张量\n",
    "print(reshaped_tensor)\n",
    "# 张量转置\n",
    "transposed_tensor = tensor_from_list.t()\n",
    "print(transposed_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2809a6",
   "metadata": {},
   "source": [
    "**数学计算**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d432cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_o = torch.ones(1,3)\n",
    "tensor_rand = torch.randn(1,3)\n",
    "print(tensor_o, tensor_rand)\n",
    "\n",
    "#加法操作\n",
    "tensor_sum = tensor_o + tensor_rand\n",
    "print(\"sum:\", tensor_sum)\n",
    "\n",
    "# 乘法操作: 注意matmul是典型的矩阵乘法\n",
    "product_tensor = torch.matmul(tensor_sum, tensor_o.t())\n",
    "print(product_tensor)\n",
    "product_tensor_2 = torch.matmul(tensor_sum.t(), tensor_o)\n",
    "print(product_tensor_2)\n",
    "\n",
    "# 广播计算\n",
    "tensor_o_broad = tensor_o * 3\n",
    "print(tensor_o_broad)\n",
    "tensor_o_broad_2 = tensor_o_broad + 2\n",
    "print(tensor_o_broad_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e4315f",
   "metadata": {},
   "source": [
    "## 自动求导\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3770440",
   "metadata": {},
   "source": [
    "# 自动求导\n",
    "pytorch自动求导的核心是torch.autograd模块，它为对张量的所有操作提供了自动求导服务，其核心部分包含:\n",
    "+ tensor\n",
    "+ 计算图\n",
    "+ 梯度计算\n",
    "+ 梯度累计\n",
    "+ 离散跟踪"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075be503",
   "metadata": {},
   "source": [
    "如果张量的requires_grad属性被设置为True，那么对它的每一步操作都将被跟踪。当结束计算后，可以调用**backward()**方法，来自动计算所有参数的梯度，注意这个梯度是**累加的**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef5f8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(3, 3, requires_grad = True)\n",
    "print(x.grad_fn)\n",
    "# 由于x是用户创建的叶子节点，因此没有跟踪计算图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3089b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones(2,2, requires_grad= True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f247a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对张量进行一次计算\n",
    "y = x ** 2\n",
    "print(y)\n",
    "print(y.grad_fn)\n",
    "# more\n",
    "z = y * y * 3\n",
    "out = z.mean()\n",
    "print(z, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c69ff9",
   "metadata": {},
   "source": [
    "由于y是对x进行操作的结果，因此这个操作会被跟踪，y的grad_fn属性为grad_fn=<PowBackward0>, 字面上看是幂计算反向传播。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bd9702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# requires_grad属性默认是false\n",
    "a = torch.randn(3,2)\n",
    "a = ((a * 3) / (a - 1))\n",
    "print(a.requires_grad)\n",
    "# .requires_grad_()方法可以原地修改张量的requires_grad属性\n",
    "a.requires_grad_(True)\n",
    "b = (a * a).sum()\n",
    "print(b.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3b897b",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## 梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3e564e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对out反向传播\n",
    "out.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78609c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 看看d(out)/dx\n",
    "print(x)\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061cb172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 雅可比向量积的例子:\n",
    "j = torch.randn(3, requires_grad=True)\n",
    "print(j)\n",
    "\n",
    "k = j * 2\n",
    "m = 0\n",
    "while k.data.norm() < 1000:\n",
    "    k = k * 2\n",
    "    m = m + 1\n",
    "print(k)\n",
    "print(m)\n",
    "# 此时k已经不再是标量，autograd不能直接计算梯度，因此只可以求雅可比向量积。\n",
    "v = torch.tensor([0.1, 1.0, 0.0001],dtype=torch.float)\n",
    "k.backward(v)\n",
    "print(j.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659c80a0",
   "metadata": {},
   "source": [
    "注意，auto_grad只能直接求**标量**结果的反向传播结果。如果结果是向量的话，对所有输入求导就会得到一个**雅可比矩阵**，而不是该输入的梯度值。因此，如果最终结果是向量的话，backward()需要引入一个与输出同维度的权重向量。\n",
    "\n",
    "___\n",
    "\n",
    "***梯度的累加机制***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a73a4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果不手动对参数的梯度清零的话，其梯度会一直累加\n",
    "out2 = x.sum()\n",
    "out2.backward()\n",
    "print(x.grad)\n",
    "out3 = x.sum()\n",
    "x.grad.data.zero_()\n",
    "out3.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b859f509",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## 离散追踪\n",
    "推理或者验证模型的时候，我们不希望数值计算过程被追踪，因为那样会消耗额外的内存与算力。此时使用torch.no_grad()来临时将tensor的requires_grad属性设置为False。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c48a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(j.requires_grad)\n",
    "print((j ** 2).requires_grad)\n",
    "\n",
    "with torch.no_grad():\n",
    "    print((j ** 2).requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a91dc0e",
   "metadata": {},
   "source": [
    "___\n",
    "tip:如果我们希望改变一个tensor的值，却不想该百年它的autograd记录，那么就直接对tensor.data属性进行操作："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1a4e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones(1, requires_grad=True)\n",
    "\n",
    "print(x.data)  # 其实还是一个tensor\n",
    "print(x.data.requires_grad)\n",
    "\n",
    "y = 2 * x\n",
    "x.data *= 100 # 只改变了值，不会记录在计算图，所以不会影响梯度传播\n",
    "y.backward()\n",
    "print(x)\n",
    "print(x.grad)  # 发现导数为2， 与100无关"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3309e0",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## grad_fn属性详解\n",
    "\n",
    "当我们对张量进行运算的时候，得到的张量的grad_fn会自动记录该操作，**并指向一个Function对象**，该对象复制前向传播和反向传播。tensor与Function共同组成一个无环有向的计算图。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6993d5dd",
   "metadata": {},
   "source": [
    "# 多gpu并行计算"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3296bd25",
   "metadata": {},
   "source": [
    "### 什么是CUDA?\n",
    "CUDA是英伟达GPU的并行运算框架。对GPU的编程是使用CUDA语言完成的。然而pytorch的cuda意思是我们即将使用GPU来处理数据和模型。\n",
    "\n",
    "当我们希望把模型或者数据从cpu迁移到gpu时，就需要使用.cuda()方法（默认0号gpu）。\n",
    "tips：\n",
    "+ pytorch目前不支持amd的opengl接口\n",
    "+ 避免频繁地将数据在cpu和gpu之间切换\n",
    "+ 进行简单操作时，使用cpu\n",
    "\n",
    "——————\n",
    "\n",
    "如何设置默认显卡？两种方法\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993a2c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    " #设置在文件最开始部分\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICE\"] = \"2\" # 设置默认的显卡\n",
    "# 或者\n",
    "CUDA_VISBLE_DEVICE=0,1 python train.py # 使用0，1两块GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cdc78cb",
   "metadata": {},
   "source": [
    "## 常见的并行训练方法：\n",
    "\n",
    "**1.mambaout,模型拆分**  \n",
    "![模型拆分图解](https://datawhalechina.github.io/thorough-pytorch/_images/model_parllel.png)  \n",
    "该方法难在gpu之间的通信\n",
    "\n",
    "**2.同一层任务分不到不同数据中**\n",
    "这种方法将同一层模型做拆分，不太理解  \n",
    "\n",
    "**3.不同数据拆分到不同设备(数据并行方式, data parallelism)**  \n",
    "![](https://datawhalechina.github.io/thorough-pytorch/_images/data_parllel.png)  \n",
    "该方法的逻辑是将相同的模型复制到各个显卡中，然后将数据切分，让各个显卡训练数据的一部分，最后进行汇总反向传播。这样可以解决通信问题。\n",
    "\n",
    "___\n",
    "\n",
    "\n",
    "### 多卡训练 \n",
    "pytorch提供了data parallel(DP)方式和DistributedDataParallel(DDP)两种多卡训练方式"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a9c48c",
   "metadata": {},
   "source": [
    "***使用CUDA加速训练***  \n",
    "**单卡训练**  \n",
    "非常简单，只要将模型和数据.cuda()就行了  \n",
    "首先要手动指定对程序可见的gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb7d547",
   "metadata": {},
   "source": [
    "**多卡DP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5abc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1,2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c2e3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "model.cuda() # 模型显示转移到CUDA上\n",
    "\n",
    "if torch.cuda.device_count() > 1: # 含有多张GPU的卡\n",
    "\tmodel = nn.DataParallel(model) # 单机多卡DP训练"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eccc04f",
   "metadata": {},
   "source": [
    "DP的抽象过程，数据被分为多个子集后，分别在各个gpu计算梯度，最后把梯度汇总到一个主gpu上进行参数的更新，这样会使得主gpu的工作负担明显大于其他gpu，成为性能瓶颈。此外，DP只适合单机模式。**注意DP是单进程多线程**\n",
    "\n",
    "问题：既然python解释器有GIL锁，为什么限制不了DP的加速？\n",
    "因为pytorch数据运行于gpu上，由CUDA和其他GPU加速库管理，不受python解释器管理。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99cd18b",
   "metadata": {},
   "source": [
    "**多机多卡DDP**  \n",
    "DDP是一种多卡多进程方式，每个进程独立运行在一个gpu上，每个gpu独立更新参数，使用高效的通信机制进行梯度信息同步。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c76e7f",
   "metadata": {},
   "source": [
    "## GIL锁对于DP与DDP的影响？\n",
    "由于模型训练大部分内容是在gpu上运行的，因此对于DP，GIL锁对工作的大部分内容几乎没有影响。\n",
    "但是对于**运行于cpu的数据预处理加载和IO操作，还有数据后处理和日志记录等**，可能成为性能瓶颈。\n",
    "但是对于多进程的DDP，由于各个进程都有独立的python解释器，实现了真正的并行运行，因此不受GIL影响。\n",
    "\n",
    "这对于严重依赖 Python runtime 的 models 而言，比如说包含 RNN 层或大量小组件的 models 而言，这尤为重要。什么是python runtime？？？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611462c7",
   "metadata": {},
   "source": [
    "# 深度学习训练的整体流程\n",
    "+ 数据预处理： 数据格式统一、异常数据清除、数据变换\n",
    "+ 划分训练集、验证集、测试集（可以使用sklearn自带的test_train_split函数）\n",
    "+ 模型选择、损失函数、优化方法\n",
    "+ 超参数设置\n",
    "+ 使用模型拟合训练数据集，在验证集、测试机上评估模型表现\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d39b21",
   "metadata": {},
   "source": [
    "## 包的导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81683703",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11a6bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 显式指定gpu\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0, 1' #指明gpu为01\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available else cpu)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cce447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置一些超参数\n",
    "batch_size = 16\n",
    "\n",
    "lr = 1e-4\n",
    "\n",
    "epoch = 100\n",
    "# 当然我们可以选择把超参数存储在yaml里面"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57de9bf5",
   "metadata": {},
   "source": [
    "## 数据读入\n",
    "+ dataset定义数据格式和数据变形形式\n",
    "+ dataloader以迭代的方式，向模型输入批次数据\n",
    "\n",
    "___\n",
    "\n",
    "## dataset\n",
    "**使用torch自建的dataset ImageFolder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356d94bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以cifar10数据集构建Dataset类的方式\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "# 这里使用了PyTorch自带的ImageFolder类的用于读取按一定结构存储的图片数据（path对应图片存放的目录，目录下包含若干子目录，每个子目录对应属于同一个类的图片）\n",
    "train_data = datasets.ImageFolder(train_path, transfor=data_transform)\n",
    "val_data = datasets.ImageFolder(val_path, transform=data_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3844a97b",
   "metadata": {},
   "source": [
    "**使用自定义的dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4f0bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    # 注意实现Dataset父类\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        image1.jpg, 0\n",
    "        image2.jpg, 1\n",
    "        ......\n",
    "        image9.jpg, 9\n",
    "        \n",
    "        \"\"\"\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        # 数据加载\n",
    "        image = read_image(img_path)\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24283aca",
   "metadata": {},
   "source": [
    "构建完成dataset以后，就可以使用dataloader批次读入数据了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026d5e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, num_workers=4, shuffle=True, drop_last=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size, num_workers=4, shuffle=False)\n",
    "# 参数解析\n",
    "# num_workers, cpu读取数据的进程数\n",
    "# drop_last, 对于最后达不到batch_size数量的样本，是否丢弃？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4383a8e8",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "# 模型构建\n",
    "**Module 类**是 torch.nn 模块里提供的一个模型构造类，是所有神经网络模块的基类，我们可以继承它来定义我们想要的模型。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "374e7a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用nn.Module构建多层感知机\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    # 在__init__中构建神经网络\n",
    "    def __init__(self, **kwargs):\n",
    "    # 调用MLP父类Block的构造函数来进行必要的初始化。这样在构造实例时还可以指定其他函数\n",
    "        super(MLP, self).__init__(**kwargs)\n",
    "        self.hidden = nn.Linear(784,256)\n",
    "        self.act = nn.ReLU()\n",
    "        self.output = nn.Linear(256, 10)\n",
    "    \n",
    "    # 定义模型的前向计算\n",
    "    def forward(self, x):\n",
    "        o = self.act(self.hidden(x))\n",
    "        return self.output(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba250603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (hidden): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (act): ReLU()\n",
      "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1897, -0.2245, -0.0114, -0.3305,  0.2267, -0.1157,  0.2367, -0.0760,\n",
       "          0.0160,  0.0921],\n",
       "        [-0.0816, -0.0649,  0.1001, -0.0160,  0.1412, -0.2122, -0.3227, -0.3230,\n",
       "         -0.2738, -0.1120]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 随机设置一个输入\n",
    "x = torch.randn(2, 784) # 第一维是batch\n",
    "net = MLP()\n",
    "print(net)\n",
    "net(x)  # 前向计算"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00db050",
   "metadata": {},
   "source": [
    "### 深度学习有各种各样的层, 本节学习使用torch构建自定义层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96de4406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 不含参数的层\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class MyLayer(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MyLayer, self).__init__(**kwargs)\n",
    "    def forward(self, x):\n",
    "        return x - x.mean()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82aeaee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyListDense(\n",
      "  (params): ParameterList(\n",
      "      (0): Parameter containing: [torch.float32 of size 4x4]\n",
      "      (1): Parameter containing: [torch.float32 of size 4x4]\n",
      "      (2): Parameter containing: [torch.float32 of size 4x4]\n",
      "      (3): Parameter containing: [torch.float32 of size 4x1]\n",
      "  )\n",
      ")\n",
      "MyDictDense(\n",
      "  (params): ParameterDict(\n",
      "      (linear1): Parameter containing: [torch.FloatTensor of size 4x4]\n",
      "      (linear2): Parameter containing: [torch.FloatTensor of size 4x1]\n",
      "      (linear3): Parameter containing: [torch.FloatTensor of size 4x2]\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 自定义参数的层，注意Parameter是Tensor的子类型，会被自动添加到模型的参数列表之中,使之可以训练\n",
    "# 这样的话，似乎就可以实现模型手撕了\n",
    "class MyListDense(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyListDense, self).__init__()\n",
    "        self.params = nn.ParameterList([nn.Parameter(torch.randn(4, 4)) for i in range(3)])\n",
    "        self.params.append(nn.Parameter(torch.randn(4, 1)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i in range(len(self.params)):\n",
    "            # mm，仅仅可以对付二维矩阵乘法\n",
    "            x = torch.mm(x, self.params[i])\n",
    "        return x\n",
    "net = MyListDense()\n",
    "print(net)\n",
    "\n",
    "class MyDictDense(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyDictDense, self).__init__()\n",
    "        self.params = nn.ParameterDict({\n",
    "                'linear1': nn.Parameter(torch.randn(4, 4)),\n",
    "                'linear2': nn.Parameter(torch.randn(4, 1))\n",
    "        })\n",
    "        self.params.update({'linear3': nn.Parameter(torch.randn(4, 2))}) # 新增\n",
    "\n",
    "    def forward(self, x, choice='linear1'):\n",
    "        return torch.mm(x, self.params[choice])\n",
    "\n",
    "net = MyDictDense()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360a1002",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "### 卷积层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eaae9455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 手撕二维卷积！！！\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "def corr2d(X, K):\n",
    "    h, w = K.shape\n",
    "    print(h,w)\n",
    "    X, K = X.float(), K.float()\n",
    "    Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i, j] = (X[i: i + h, j: j + w] * K).sum()\n",
    "    return Y\n",
    "\n",
    "class Conv2D(nn.Module):\n",
    "    def __init__(self, kernel_size):\n",
    "        super(Conv2D, self).__init()\n",
    "        # super 方法用于为子类调用父类方法，type参数\n",
    "        # 传入类型， obj传入实例，在类定义中, obj传入\n",
    "        # self\n",
    "        self.weight = nn.Parameter(torch.randn(kernel_size))\n",
    "        self.bias = nn.Parameter(torch.randn(1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return corr2d(x, self.weight) + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "487c328a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "# 使用padding进行same卷积\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "def comp_conv2d(conv2d, X):\n",
    "    X = X.view((1,1) + X.shape) # 为X加入批次和通道维度\n",
    "    Y = conv2d(X)\n",
    "    return Y.view(Y.shape[2:]) # 滤除批次和通道维度\n",
    "\n",
    "# 对输入左右padding两行\n",
    "conv2d = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=3, padding= 1)\n",
    "\n",
    "X = torch.rand(8,8)\n",
    "# 注意卷积之后前后变换公式: y = (x - h + 2 * p)/s + 1, 注意向下取整\n",
    "print(comp_conv2d(conv2d, X).shape)\n",
    "\n",
    "# 使用高宽不一致的卷积核\n",
    "conv2d = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=(5, 3), padding=(2, 1))\n",
    "print(comp_conv2d(conv2d, X).shape)\n",
    "\n",
    "# 引入stride\n",
    "conv2d = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=(3, 5), padding= (0, 1), stride = (3, 4))\n",
    "print(comp_conv2d(conv2d, X).shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5e3ba8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5., 6.],\n",
      "        [8., 9.]])\n",
      "tensor([[2.5000, 3.5000],\n",
      "        [6.0000, 7.0000]])\n"
     ]
    }
   ],
   "source": [
    "# 手撕池化层\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "def pool2d(X, pool_size, mode = 'max'):\n",
    "    p_h, p_w = pool_size\n",
    "    Y = torch.zeros((X.shape[0] - p_h + 1, X.shape[1] - p_w + 1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            if mode == 'max':\n",
    "                Y[i, j] = X[i: i + p_h, j: j + p_w].max()\n",
    "            elif mode == 'avg':\n",
    "                Y[i, j] = X[i: i + p_h, j: j + p_w].mean()\n",
    "    return Y\n",
    "\n",
    "X = torch.tensor([[0,1,2],[4,5,6],[7,8,9]], dtype = torch.float)\n",
    "print(pool2d(X, (2,2)))\n",
    "print(pool2d(X,(2,2), \"avg\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80120fb",
   "metadata": {},
   "source": [
    "## 卷积层的计算量\n",
    "**输出维度**：假设输入特征的shape为H * W * C， 卷积核大小为h * w, 数量为c， 步长为s， padding为n，求输出的shape：\n",
    "$$\\left(\\left\\lfloor \\frac{H - h + 2n}{s} \\right\\rfloor + 1, \\left\\lfloor \\frac{W - w + 2n}{s} \\right\\rfloor + 1, c \\right)$$\n",
    "**总计算量**: 在上述背景下，所需的总计算量：  \n",
    "从输出角度看比较简单理解, 设输出维度分别是$H_o$, $W_o$, 输出的每一个数据点所需要的乘法是$H_o * W_o * h * w * C * c$，加法操作是$H_o * W_o * C * (h * w * c - 1)$\n",
    "即$$\\text{乘法计算量} = \\left( \\left\\lfloor \\frac{H - h + 2n}{s} \\right\\rfloor + 1 \\right) \\times \\left( \\left\\lfloor \\frac{W - w + 2n}{s} \\right\\rfloor + 1 \\right) \\times h \\times w \\times C \\times c$$\n",
    "**感受野**：卷积神经网络的感受野指的是某层神经网络的神经元能感受到输入层的特征数量。  \n",
    "感受野计算公式：\n",
    "$$R_{l+1} = R_l + (k - 1) \\cdot \\prod_{i=1}^{l} s_i$$ \n",
    "因此感受野受到以下因素影响：\n",
    "+ 池化可以使得数据分辨率降低，使得后序层的感受野增大\n",
    "+ 卷积核宽度，宽度越宽，感受野越大\n",
    "+ 步长，更大的步长可以增加感受野，但也会使得特征图分辨率下降加速\n",
    "+ padding\n",
    "+ 神经网络深度\n",
    "+ 膨胀卷积\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fe0017",
   "metadata": {},
   "source": [
    "### 关于U-NET中上采样或者解码层的一些补充\n",
    "上采样的两种方法：\n",
    "+ 双线性插值上采样(无需学习): 使用插值的方法增加像素点，通过双线性插值可以得到平滑输出但是\n",
    "失去高频细节\n",
    "+ 转置卷积(需要学习)\n",
    "\n",
    "**转置卷积的实现：** 首先是输入扩展，在每个元素周围插入stride-1个0，然后使用常规的卷积方式进行卷积。  \n",
    "最终输出尺寸是:\n",
    "$$H_{\\text{out}} = s \\cdot (H - 1) + k - 2p$$\n",
    "$$W_{\\text{out}} = s \\cdot (W - 1) + k - 2p$$\n",
    "其中k是卷积核尺寸，p是padding。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d01417",
   "metadata": {},
   "source": [
    "## RNN\n",
    "![](RNN.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23723b88",
   "metadata": {},
   "source": [
    "pytorch 中使用 nn.RNN 类来搭建基于序列的循环神经网络，它的构造函数有以下几个参数：\n",
    "\n",
    "- input_size：输入数据X的特征值的数目。\n",
    "- hidden_size：隐藏层的神经元数量，也就是隐藏层的特征数量。在torch中也是该RNN输出特征数量。\n",
    "- num_layers：循环神经网络的层数，默认值是 1。\n",
    "- bias：默认为 True，如果为 false 则表示神经元不使用 bias 偏移参数。\n",
    "- batch_first：如果设置为 True，则输入数据的维度中第一个维度就是 batch 值，默认为 False。默认情况下第一个维度是序列的长度， 第二个维度才是 - - batch，第三个维度是特征数目。\n",
    "- dropout：如果不为空，则表示最后跟一个 dropout 层抛弃部分数据，抛弃数据的比例由该参数指定。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66156cb2",
   "metadata": {},
   "source": [
    "在原始RNN中，记忆的传递仅仅依赖于隐藏状态，计算公式如下：\n",
    "$$h_t = f(W_{hx}x_t + W_{hh}h_{t-1} + b_h)$$\n",
    "$$\\hat{y}_t = g(W_{yh}h_t + b_y)$$\n",
    "注意，RNN每个时间步共享一个RNN单元，意味着参数W和b在每个时间步都是不变的。  \n",
    "因此，RNN可以认为是一个带有记忆传递的全连接层。\n",
    "\n",
    "**总的计算量**: 在ht的计算过程中，不计激活函数的话，两个矩阵乘法所需要的乘法数量为$2K^2$, 需要的加法数量为$2K(K-1)$, 此外还要计入与偏执的2K次加法，因此总的计算量为$4K^2$\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a8a1cf",
   "metadata": {},
   "source": [
    "### RNN的梯度消失与梯度爆炸问题\n",
    "RNN的损失为每个时间步损失的总和：\n",
    "![](https://pic3.zhimg.com/v2-54298417fcad6982932fbf3164a4c29a_r.jpg)\n",
    "其反向传播使用跨越时间反向传播算法(BPTT)  \n",
    "$$\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{W}} = \\sum_{t=1}^{T} \\frac{\\partial \\mathcal{L}_t}{\\partial \\mathbf{W}} = \\sum_{t=1}^{T} \\frac{\\partial \\mathcal{L}_t}{\\partial \\mathbf{y}_t} \\frac{\\partial \\mathbf{y}_t}{\\partial \\mathbf{h}_t} \\underbrace{\\frac{\\partial \\mathbf{h}_t}{\\partial \\mathbf{h}_k}}_{*} \\frac{\\partial \\mathbf{h}_k}{\\partial \\mathbf{W}}$$\n",
    "其中  \n",
    "$$\\frac{\\partial \\mathbf{h}_t}{\\partial \\mathbf{h}_k} = \\frac{\\partial \\mathbf{h}_t}{\\partial \\mathbf{h}_{t-1}} \\frac{\\partial \\mathbf{h}_{t-1}}{\\partial \\mathbf{h}_{t-2}} \\cdots \\frac{\\partial \\mathbf{h}_{k+1}}{\\partial \\mathbf{h}_k} = \\prod_{i=k+1}^{t} \\frac{\\partial \\mathbf{h}_i}{\\partial \\mathbf{h}_{i-1}}$$\n",
    "这个雅可比矩阵可以进一步分解，不同时间步的隐藏状态计算公式共享一个W\n",
    "$$\\prod_{i=k+1}^{t} \\frac{\\partial \\mathbf{h}_i}{\\partial \\mathbf{h}_{i-1}} = \\prod_{i=k+1}^{t} \\mathbf{W}^\\top \\operatorname{diag} \\left[ f'(\\mathbf{h}_{i-1}) \\right]$$\n",
    "对W进行矩阵分解\n",
    "$$\\mathbf{W} = \\mathbf{V} \\operatorname{diag}(\\lambda)\\mathbf{V^{-1}}$$\n",
    "由此可知，t个W相乘以后，如果W的最大特征值大于1，会导致梯度爆炸，最大特征值小于1，会导致梯度消失。因此为了抑制梯度消失与梯度爆炸问题，每次BPPT只进行固定的时间步数，从而导致了RNN无法处理长序列记忆问题。  \n",
    "此外也可以采取梯度裁剪来抑制梯度爆炸。  \n",
    "梯度消失问题稍微难解决问题，最容易理解的就是直接使用LSTM或RNN。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c04943",
   "metadata": {},
   "source": [
    "## LSTM\n",
    "LSTM解决了RNN只能解决短期依赖关系的问题，加入门控机制，来实现对记忆信息的控制，达到选择性遗忘或记忆之前的内容，从而学会长期依赖。 \n",
    "![](https://pic1.zhimg.com/v2-2033db91e70559f363eca4bf365b8c44_r.jpg) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7722a8f5",
   "metadata": {},
   "source": [
    "\n",
    "LSTM包含三个门：\n",
    "+ 输入门:\n",
    "+ 输出门\n",
    "+ 遗忘门  \n",
    "这三个门的计算公式一致，只是参数独立: \n",
    "$$\\mathbf{i}_t = \\sigma(\\mathbf{W}_i \\mathbf{x}_t + \\mathbf{U}_i \\mathbf{h}_{t-1} + \\mathbf{b}_i)$$\n",
    "$$\\mathbf{f}_t = \\sigma(\\mathbf{W}_f \\mathbf{x}_t + \\mathbf{U}_f \\mathbf{h}_{t-1} + \\mathbf{b}_f)$$\n",
    "$$\\mathbf{o}_t = \\sigma(\\mathbf{W}_o \\mathbf{x}_t + \\mathbf{U}_o \\mathbf{h}_{t-1} + \\mathbf{b}_o)$$\n",
    "\n",
    "此外，LSTM相比于RNN多加入一个记忆单元(cell)，它的作用是保持t时刻的一个关键信息，并使之可调控地保存一段时间。\n",
    "候选cell的更新公式如下  \n",
    "$$\\tilde{\\mathbf{c}_t} = \\operatorname{tanh}(\\mathbf{W}_o \\mathbf{x}_t + \\mathbf{U}_o \\mathbf{h}_{t-1} + \\mathbf{b}_o)$$\n",
    "遗忘门、输入门的作用是决定候选记忆单元与t-1时间步记忆单元之间的混合比例，并形成当前时间步的记忆单元，输出门的作用是如何把当前记忆单元映射为当前隐藏状态(输出门决定当前多少记忆单元要输出为隐藏状态)。  \n",
    "forget gate | input gate |  result  \n",
    "\n",
    " 1  |  0  |  保留上一时刻的状态   \n",
    " 1  |  1  |  保留上一时刻和添加新信息   \n",
    " 0  |  1  |  清空历史信息，引入新信息   \n",
    " 0  |  0  |  清空所有新旧信息    \n",
    " 这样看的话，举一个极端案例，如果遗忘门始终为1，输入门始终为0，那么就无论多少时间步，最初的记忆总能影响到最终结果。\n",
    " ### 为什么LSTM能抑制梯度消失问题呢？  \n",
    " 因为LSTM已经不再直接把隐藏状态作为记忆传递，而是通过一个可调控的记忆单元cell来传递记忆，从而使得梯度逆时间步流动时，可以直接通过遗忘门与输入门回到更早时间步，从而避免了梯度消失。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da216f84",
   "metadata": {},
   "source": [
    "## GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f7c13c",
   "metadata": {},
   "source": [
    "\n",
    "LSTM有三个门，以及记忆单元计算，这导致了大量的权重矩阵需要学习，降低了训练速度。因此基于LSTM进行简化得到了GRU，它简化了LSTM输入门与遗忘门之间的互补关系，并取消了记忆单元，如同RNN一样直接使用隐藏状态传递记忆。  \n",
    "![](https://pic2.zhimg.com/v2-6a83a3f4783bddb3479436724aa9150d_r.jpg)  \n",
    "如图，GRU只要两个门：\n",
    "+ 重置reset门\n",
    "+ 更新update门\n",
    "重置门用于生成候选隐藏状态，更新门以一定比例混合候选隐藏状态和上一步的隐藏状态。\n",
    "$$\\begin{align*}\n",
    "r_t &= \\sigma(\\mathbf{W}_r \\mathbf{x}_t + \\mathbf{U}_r \\mathbf{h}_{t-1} + \\mathbf{b}_r) \\\\\n",
    "z_t &= \\sigma(\\mathbf{W}_z \\mathbf{x}_t + \\mathbf{U}_z \\mathbf{h}_{t-1} + \\mathbf{b}_z) \\\\\n",
    "\\tilde{\\mathbf{h}}_t &= \\tanh(\\mathbf{W}_h \\mathbf{x}_t + r_t \\odot (\\mathbf{U}_h \\mathbf{h}_{t-1}) + \\mathbf{b}_h) \\\\\n",
    "\\mathbf{h}_t &= z_t \\odot \\mathbf{h}_{t-1} + (1 - z_t) \\odot \\tilde{\\mathbf{h}}_t\n",
    "\\end{align*}\n",
    "$$\n",
    "观察公式发现，当重置门的值为1的时候，GRU与RNN抑制。更新门数值为1的时候，改GRU就完全变成记忆传递通道，与当前输入无关了。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14c7d35",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "# 模型初始化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50aa4df6",
   "metadata": {},
   "source": [
    "### 为什么参数初始化不能全部为0  \n",
    "当网络中所有权重都初始化为0时，对于任何隐藏层，所有神经元在前向传播和反向传播过程中的行为都会完全相同。这意味着每一层的每个神经元将计算出相同的输出，并且在反向传播中也会接收到相同的梯度。结果是，即使网络的参数被更新，每个权重也会保持相同，这使得隐藏层的多个神经元没有区分开来，因此无法学习到多样化的特征或模式。  \n",
    "此外，对于一些过零的激活函数（如Sigmoid或Tanh），全部初始化为0也会导致梯度消失问题，当激活函数的输入接近0的时候，其反向传播获得的梯度也会接近0。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae75b16",
   "metadata": {},
   "source": [
    "**nn.init中提供了一些初始化的方法，这里直接复制**\n",
    " 1 . torch.nn.init.uniform_(tensor, a=0.0, b=1.0)   \n",
    " 2 . torch.nn.init.normal_(tensor, mean=0.0, std=1.0)   \n",
    " 3 . torch.nn.init.constant_(tensor, val)   \n",
    " 4 . torch.nn.init.ones_(tensor)   \n",
    " 5 . torch.nn.init.zeros_(tensor)   \n",
    " 6 . torch.nn.init.eye_(tensor)   \n",
    " 7 . torch.nn.init.dirac_(tensor, groups=1)   \n",
    " 8 . torch.nn.init.xavier_uniform_(tensor, gain=1.0)   \n",
    " 9 . torch.nn.init.xavier_normal_(tensor, gain=1.0)   \n",
    " 10 . torch.nn.init.kaiming_uniform_(tensor, a=0, mode='fan__in', nonlinearity='leaky_relu')   \n",
    " 11 . torch.nn.init.kaiming_normal_(tensor, a=0, mode='fan_in', nonlinearity='leaky_relu')   \n",
    " 12 . torch.nn.init.orthogonal_(tensor, gain=1)   \n",
    " 13 . torch.nn.init.sparse_(tensor, sparsity, std=0.01)   \n",
    " 14 . torch.nn.init.calculate_gain(nonlinearity,  \n",
    " 方法带有下划线，意味着这些方法能原地改变张量的值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f046390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# isinstance方法可以判定某个实例是不是属于某个类型\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "conv = nn.Conv2d(1,3,3)\n",
    "linear = nn.Linear(10,1)\n",
    "\n",
    "\n",
    "print(isinstance(conv, nn.Conv2d))\n",
    "print(isinstance(linear, nn.Conv2d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6edda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看一波层的参数\n",
    "print(conv.weight.data)\n",
    "# 3*3的卷积核，输出通道为3，似乎创建出来就被自动初始化了\n",
    "print(linear.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b43a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对conv进行kaiming初始化\n",
    "torch.nn.init.kaiming_normal_(conv.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e65f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对linear进行常数初始化\n",
    "torch.nn.init.constant_(linear.weight.data,0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbbc653",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "# 损失函数\n",
    "损失函数衡量了预测信息与标签信息之间的差距，用于为模型训练提供负反馈，是反向传播的起点。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b572463",
   "metadata": {},
   "source": [
    "\n",
    "___\n",
    "\n",
    "### PMSQE损失：基于感知指标的语言质量评估\n",
    "传统的均方误差损失MSE只考虑预测语音与目标语音之间的功率谱之间的均方误差，仅仅在数学上缩小了二者功率谱的差异，没有考虑人耳对声音的感知特性，因此基于MSE训练出来的模型在听觉上往往不如人意。\n",
    "PMSQE在MSE的基础上，增添了两个感知扰动项：对称扰动与非对称扰动。它们是基于PESQ简化而来，其中对称扰动衡量了预测语音与目标语音之间的响度差异;非对称扰动是对对称扰动进行加权得到的，加权的值取决于对称扰动的正负，因为人耳对音量增大的敏感度高于对音量减小的敏感度，正差异会获得更大损失。\n",
    "最终MSE、对称扰动、非对称扰动共同构成了PMSQE损失。\n",
    "\n",
    "___\n",
    "### 基于pase编码器的损失：\n",
    "PASE是一个使用子监督方法训练得到的语音特征提取器，其提取出来的语音特征被证明比传统的MFCC谱更有更好性能。基于PASE模型得到音频的embedding，计算预测语音与目标语音embedding之间的MSE。\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab52be2",
   "metadata": {},
   "source": [
    "# 优化器\n",
    "优化器是根据网络反向传播的梯度信息来**更新网络的参数**，以起到降低loss函数计算值，使得模型输出更加接近真实标签。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eaec480",
   "metadata": {},
   "source": [
    "**torch提供了一个优化器库torch.optim**提供多种优化器\n",
    "torch.optim.SGD\n",
    "\n",
    "torch.optim.ASGD\n",
    "\n",
    "torch.optim.Adadelta\n",
    "\n",
    "torch.optim.Adagrad\n",
    "\n",
    "torch.optim.Adam\n",
    "...\n",
    "这些优化器都继承自基类**Optimizer**,定义:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d1e7414",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer(object):\n",
    "    def __init__(self, params, defaults):        \n",
    "        self.defaults = defaults # 存储一些通用超参数，比如momentum的beta，rmsprop的beta\n",
    "        self.state = defaultdict(dict) # 优化器状态参数缓存，比如累加的梯度\n",
    "        self.param_groups = [] # 字典列表，每个元素是个字典，包含需要训练的parameter，对应的学习率，权重衰减\n",
    "\n",
    "    # 介绍Optimizer的一些方法\n",
    "    # 清空梯度缓存\n",
    "    def zero_grad(self, set_to_none: bool = False):\n",
    "        for group in self.param_groups:\n",
    "            for p in group['params']:\n",
    "                if p.grad is not None:  #梯度不为空\n",
    "                    if set_to_none: \n",
    "                        p.grad = None\n",
    "                    else:\n",
    "                        if p.grad.grad_fn is not None:\n",
    "                            p.grad.detach_()  # 断开计算图\n",
    "                        else:\n",
    "                            p.grad.requires_grad_(False)\n",
    "                        p.grad.zero_()# 梯度设置为0\n",
    "\n",
    "    # 执行参数更新\n",
    "    def step(self, closure): \n",
    "        raise NotImplementedError\n",
    "\n",
    "    # 添加参数组\n",
    "    def add_param_group(self, param_group):\n",
    "        pass\n",
    "\n",
    "    # 加载状态参数字典，用于断点续训练\n",
    "    def load_state_dict(self, state_dict):\n",
    "        ...\n",
    "\n",
    "    def cast(param, value):\n",
    "        ...\n",
    "\n",
    "    # Update parameter groups, setting their 'params' value\n",
    "    def update_group(group, new_group):\n",
    "       ...\n",
    "       \n",
    "    # 获取当前优化器状态信息字典\n",
    "    def state_dict(self):\n",
    "        ...\n",
    "\n",
    "    def pack_group(group):\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70072e16",
   "metadata": {},
   "source": [
    "\n",
    "### 随机梯度下降法SGD\n",
    "在torch中，欲实现SGD，需要设置batch_size为1。即计算一个样本的损失，就更新参数。\n",
    "+ 缺陷：噪声与抖动非常大，而且永远无法收敛至最小值。\n",
    "\n",
    "### mini-batch梯度下降法\n",
    "将m个样本拼接成一个batch，累加m个样本的梯度求平均，然后更新参数，噪声相对于SGD小。当然性能消耗也会大于SGD。\n",
    "\n",
    "### batch梯度下降法\n",
    "将所有样本一次性输入，累加梯度后求平均，噪声非常小，但数据量巨大，在现代深度学习任务中几乎不可能实现。\n",
    "\n",
    "## 知识点：指数加权平均\n",
    "指数加权平均是一种计算机易实现的数据平滑处理。\n",
    "$v_t = \\beta v_{t-1} + (1 - \\beta)\\theta_t$  \n",
    "v和theta分别代表了平滑值与瞬时值。平滑窗口长度约为$\\frac{1}{1 - \\beta}$\n",
    "\n",
    "### momentum动量梯度下降法：\n",
    "momentum的核心在于指数加权平均，在梯度下降过程中，正负摆动会被平滑掉，而朝着损失下降的方向由于固定，不会被平滑。在momentum梯度下降法中，超参数包含$\\beta$与$\\alpha$，分别是指数加权平均的参数和学习率。\n",
    "\n",
    "### RMSprop梯度下降算法：\n",
    "不同于momentum仅仅平滑了梯度，RMSprop还对参数变化进行了加速。\n",
    "$$S_{dw} = \\beta S_{dw} + (1 - \\beta)dW^2$$\n",
    "$$S_{db} = \\beta S_{db} + (1 - \\beta)db^2$$\n",
    "$$W = W - \\alpha \\frac{dW}{\\sqrt{S_{dW}}}$$\n",
    "$$W = b - \\alpha \\frac{db}{\\sqrt{S_{db}}}$$  \n",
    "\n",
    "对于变化比较剧烈的参数，S会比较大，更新时会收到抑制，变化微弱的参数，更新时会得到放大。\n",
    "\n",
    "### Adam优化算法\n",
    "adam融合了momentum算法和RMSprop算法，既对梯度进行了平滑，又对参数更新进行了加速。因此同时拥有了动量梯度下降的$\\beta1$，又有了RMSprop算法$\\beta2$\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a45f22",
   "metadata": {},
   "source": [
    "## torch优化器实际操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75f54d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data of weight before step:\n",
      "tensor([[-0.5980, -2.6022],\n",
      "        [-0.2394,  0.7446]])\n",
      "The grad of weight before step:\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "# 初始化权重\n",
    "weight = torch.randn((2,2), requires_grad=True)\n",
    "# 设置梯度为全1矩阵 --> 2 * 2\n",
    "weight.grad = torch.ones((2,2))\n",
    "print(\"The data of weight before step:\\n{}\".format(weight.data))\n",
    "print(\"The grad of weight before step:\\n{}\".format(weight.grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cbae2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data of weight after step:\n",
      "tensor([[-0.6980, -2.7022],\n",
      "        [-0.3394,  0.6446]])\n",
      "The grad of weight after step:\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# 实例化优化器\n",
    "optimizer = torch.optim.SGD([weight], lr=0.1, momentum=0.9)\n",
    "# 更新下参数\n",
    "optimizer.step()\n",
    "print(\"The data of weight after step:\\n{}\".format(weight.data))\n",
    "print(\"The grad of weight after step:\\n{}\".format(weight.grad))\n",
    "# 发现参数都降低了0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfc7bc00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The grad of weight after optimizer.zero_grad():\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 梯度清零\n",
    "optimizer.zero_grad()\n",
    "print(\"The grad of weight after optimizer.zero_grad():\\n{}\".format(weight.grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd7092ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimizer.params_group is \n",
      "[{'params': [tensor([[-0.6980, -2.7022],\n",
      "        [-0.3394,  0.6446]], requires_grad=True)], 'lr': 0.1, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'maximize': False, 'foreach': None, 'differentiable': False, 'fused': None}]\n",
      "weight in optimizer:140464894949392\n",
      "weight in weight:140464894949392\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"optimizer.params_group is \\n{}\".format(optimizer.param_groups))\n",
    "print(\"weight in optimizer:{}\\nweight in weight:{}\\n\".format(id(optimizer.param_groups[0]['params'][0]), id(weight)))\n",
    "# 上面发现optimizer.param_groups[0][\"params\"[0]]和weight指向同一个对象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95c23d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimizer.param_groups is\n",
      "[{'params': [tensor([[-0.6980, -2.7022],\n",
      "        [-0.3394,  0.6446]], requires_grad=True)], 'lr': 0.1, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'maximize': False, 'foreach': None, 'differentiable': False, 'fused': None}, {'params': [tensor([[0.4579, 0.4673, 0.5956],\n",
      "        [0.7286, 0.6144, 0.7743],\n",
      "        [0.4208, 0.2964, 0.2083]], requires_grad=True)], 'lr': 0.0001, 'nesterov': True, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'maximize': False, 'foreach': None, 'differentiable': False, 'fused': None}]\n"
     ]
    }
   ],
   "source": [
    "# 添加参数：weight2\n",
    "weight = torch.rand((3,3 ), requires_grad= True)\n",
    "optimizer.add_param_group({\"params\": weight, \"lr\" :0.0001, \"nesterov\": True})\n",
    "# 查\n",
    "print(\"optimizer.param_groups is\\n{}\".format(optimizer.param_groups))\n",
    "# 发现default属性的确存储的是统一超参数，但优先级低于param_group中的超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a14eb5fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state_dict before step:\n",
      " {'state': {0: {'momentum_buffer': tensor([[1., 1.],\n",
      "        [1., 1.]])}}, 'param_groups': [{'lr': 0.1, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'maximize': False, 'foreach': None, 'differentiable': False, 'fused': None, 'params': [0]}, {'lr': 0.0001, 'nesterov': True, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'maximize': False, 'foreach': None, 'differentiable': False, 'fused': None, 'params': [1]}]}\n"
     ]
    }
   ],
   "source": [
    "# 查看优化器当前状态信息\n",
    "opt_state_dict = optimizer.state_dict()\n",
    "print(\"state_dict before step:\\n\", opt_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2277d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state_dict after step:\n",
      " {'state': {0: {'momentum_buffer': tensor([[1., 1.],\n",
      "        [1., 1.]])}}, 'param_groups': [{'lr': 0.1, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'maximize': False, 'foreach': None, 'differentiable': False, 'fused': None, 'params': [0]}, {'lr': 0.0001, 'nesterov': True, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'maximize': False, 'foreach': None, 'differentiable': False, 'fused': None, 'params': [1]}]}\n"
     ]
    }
   ],
   "source": [
    "# 50次step\n",
    "for _ in range(50):\n",
    "    optimizer.step()\n",
    "print(\"state_dict after step:\\n\", optimizer.state_dict())\n",
    "# 注意state中只存储一些当前的超参数、梯度等信息，并不存储data\n",
    "# 保存参数信息\n",
    "torch.save(optimizer.state_dict(),os.path.join(r\"D:\\pythonProject\\Attention_Unet\", \"optimizer_state_dict.pkl\"))\n",
    "print(\"----------done-----------\")\n",
    "# 加载参数信息\n",
    "state_dict = torch.load(r\"D:\\pythonProject\\Attention_Unet\\optimizer_state_dict.pkl\") # 需要修改为你自己的路径\n",
    "optimizer.load_state_dict(state_dict)\n",
    "print(\"load state_dict successfully\\n{}\".format(state_dict))\n",
    "# 输出最后属性信息\n",
    "print(\"\\n{}\".format(optimizer.defaults))\n",
    "print(\"\\n{}\".format(optimizer.state))\n",
    "print(\"\\n{}\".format(optimizer.param_groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7161328f",
   "metadata": {},
   "outputs": [],
   "source": [
    "___\n",
    "\n",
    "# 模型定义\n",
    "nn.Module是torch中所有网络模块的基类型。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f16de21",
   "metadata": {},
   "source": [
    "\n",
    "### 使用Sequential类来定义串联层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b24f6d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 直接法\n",
    "import torch.nn as nn\n",
    "net = nn.Sequential(\n",
    "    nn.Linear(784, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256,10)\n",
    ")\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01b2b66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (fc1): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (relu1): ReLU()\n",
      "  (fc2): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 使用OrderedDict\n",
    "import collections\n",
    "import torch.nn as nn\n",
    "net2 = nn.Sequential(collections.OrderedDict([\n",
    "          ('fc1', nn.Linear(784, 256)),\n",
    "          ('relu1', nn.ReLU()),\n",
    "          ('fc2', nn.Linear(256, 10))\n",
    "          ]))\n",
    "print(net2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd808de4",
   "metadata": {},
   "source": [
    "### 模型列表ModuleList\n",
    "接受子模块作为输入，可以类似list那样append和extend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54ac56e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=256, out_features=10, bias=True)\n",
      "ModuleList(\n",
      "  (0): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = nn.ModuleList([nn.Linear(784,256), nn.ReLU()])\n",
    "net.append(nn.Linear(256,10))\n",
    "print(net[-1])\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf7f4ae",
   "metadata": {},
   "source": [
    "**注意modulelist不能像sequential那样直接forward，而应该遍历列表的层分别forward**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6631493",
   "metadata": {},
   "source": [
    "# 修改现有模型\n",
    "开源模型越来越多，我们没必要手动去搓模型了。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5967bae7",
   "metadata": {},
   "source": [
    "### 篡改resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e9ea058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "import torchvision.models as models\n",
    "net = models.resnet50()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146978c4",
   "metadata": {},
   "source": [
    "如果我们希望修改model，进行十分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9b26b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Sequential(\n",
      "    (fc1): Linear(in_features=2048, out_features=128, bias=True)\n",
      "    (relu1): ReLU()\n",
      "    (dropout1): Dropout(p=0.5, inplace=False)\n",
      "    (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      "    (output): Softmax(dim=1)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 我们把最终的fc层修改为含有两个隐藏层的全链接层\n",
    "classifier = nn.Sequential(OrderedDict([\n",
    "    (\"fc1\", nn.Linear(2048, 128)),\n",
    "    ('relu1', nn.ReLU()), \n",
    "    ('dropout1',nn.Dropout(0.5)),\n",
    "    ('fc2', nn.Linear(128, 10)),\n",
    "    ('output', nn.Softmax(dim=1))\n",
    "]))\n",
    "net.fc = classifier\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f64cc5e",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "# torch中模型的输出&存储\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbe4303",
   "metadata": {},
   "source": [
    "torch的模型一般以pkl,pt或者pth三种格式存储.pt和pth必须有pytorch环境的支持,pkl更加通用而不安全.  \n",
    "pt和pth本质上是一样的,用于存储pytorch的模型和张量.  \n",
    "pkl是python的通用数据序列化格式,由python的pickle模块实现,可以序列化几乎所有python对象."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ffb180",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "model = models.resnet152(pretrained=True)\n",
    "save_dir = './resnet152.pth'\n",
    "\n",
    "# 保存整个模型\n",
    "torch.save(model, save_dir)\n",
    "# 保存模型权重\n",
    "torch.save(model.state_dict, save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27191d5",
   "metadata": {},
   "source": [
    "# 动态调整学习率\n",
    "学习率过小会造成学习缓慢，过大会导致损失震荡，因此，我们需要动态调整学习率，训练初期我们希望训练更加快速，因此学习率较大，后期为了防止损失震荡，会降低学习率。在pytorch中，可以设置一个学习率衰减策略来动态调整学习率，这个工具叫做调度器scheduler。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58ed1dc",
   "metadata": {},
   "source": [
    "\n",
    "在torch.optim.lr_scheduler模块中封装好了一系列调度器：\n",
    "lr_scheduler.LambdaLR\n",
    "\n",
    "lr_scheduler.MultiplicativeLR\n",
    "\n",
    "lr_scheduler.StepLR\n",
    "\n",
    "lr_scheduler.MultiStepLR\n",
    "\n",
    "lr_scheduler.ExponentialLR\n",
    "\n",
    "lr_scheduler.CosineAnnealingLR\n",
    "\n",
    "lr_scheduler.ReduceLROnPlateau\n",
    "\n",
    "lr_scheduler.CyclicLR\n",
    "\n",
    "lr_scheduler.OneCycleLR\n",
    "\n",
    "lr_scheduler.CosineAnnealingWarmRestarts\n",
    "\n",
    "lr_scheduler.ConstantLR\n",
    "\n",
    "lr_scheduler.LinearLR\n",
    "\n",
    "lr_scheduler.PolynomialLR\n",
    "\n",
    "lr_scheduler.ChainedScheduler\n",
    "\n",
    "lr_scheduler.SequentialLR\n",
    "\n",
    "他们都继承自_LRScheduler类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6670298e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学习率调度往往是在训练完一个epoch后执行的：\n",
    "# 选择一种优化器\n",
    "optimizer = torch.optim.Adam(...) \n",
    "# 选择上面提到的一种或多种动态调整学习率的方法\n",
    "scheduler1 = torch.optim.lr_scheduler.... \n",
    "scheduler2 = torch.optim.lr_scheduler....\n",
    "...\n",
    "schedulern = torch.optim.lr_scheduler....\n",
    "# 进行训练\n",
    "for epoch in range(100):\n",
    "    train(...)\n",
    "    validate(...)\n",
    "    optimizer.step()\n",
    "    # 需要在优化器参数更新之后再动态调整学习率\n",
    "# scheduler的优化是在每一轮后面进行的\n",
    "scheduler1.step() \n",
    "...\n",
    "schedulern.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c98460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在之前的内容中我们知道训练的权重、梯度、学习率等内容都存储在optimizer的param_group中\n",
    "# 因此如果希望自定义一个scheduler，我们的核心就是修改param_group的\"lr\"\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    lr = args.lr * (0.1 ** (epoch // 30))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr = args.lr,momentum = 0.9)\n",
    "for epoch in range(10):\n",
    "    train(...)\n",
    "    validate(...)\n",
    "    adjust_learning_rate(optimizer,epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9398b1d",
   "metadata": {},
   "source": [
    "# 深度学习模型微调\n",
    "实际任务中，我们手上的数据很少，几乎不可能直接从头训练一个模型，因为可能会导致过拟合。因此借用别人的预训练模型来进行微调显得非常重要。\n",
    "在pytorch中提供了非常多的预训练模型，比如VGG、Resnet等等。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5995df3d",
   "metadata": {},
   "source": [
    "### 微调的基本流程\n",
    "+ 在开源大量的源数据集上训练一个源模型\n",
    "+ 替换源数据集的输出层，使之适应新数据集的任务\n",
    "+ 在目标数据集上，从头训练输出层，并微调其他层。  \n",
    "![微调流程](https://datawhalechina.github.io/thorough-pytorch/_images/finetune.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3412c071",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda\\envs\\project\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "d:\\miniconda\\envs\\project\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "d:\\miniconda\\envs\\project\\lib\\site-packages\\torchvision\\models\\inception.py:43: FutureWarning: The default weight initialization of inception_v3 will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.\n",
      "  warnings.warn(\n",
      "d:\\miniconda\\envs\\project\\lib\\site-packages\\torchvision\\models\\googlenet.py:47: FutureWarning: The default weight initialization of GoogleNet will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 首先，从torchvision库搞个预训练模型下来\n",
    "# 默认情况下，models中的模型是不包含预训练参数的\n",
    "import torchvision.models as models\n",
    "resnet18 = models.resnet18(pretrained=False)\n",
    "alexnet = models.alexnet()\n",
    "vgg16 = models.vgg16()\n",
    "squeezenet = models.squeezenet1_0()\n",
    "densenet = models.densenet161()\n",
    "inception = models.inception_v3()\n",
    "googlenet = models.googlenet()\n",
    "shufflenet = models.shufflenet_v2_x1_0()\n",
    "mobilenet_v2 = models.mobilenet_v2()\n",
    "mobilenet_v3_large = models.mobilenet_v3_large()\n",
    "mobilenet_v3_small = models.mobilenet_v3_small()\n",
    "resnext50_32x4d = models.resnext50_32x4d()\n",
    "wide_resnet50_2 = models.wide_resnet50_2()\n",
    "mnasnet = models.mnasnet1_0()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d370ff0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 因此需要显式地指明使用预训练参数\n",
    "resnet18 = models.resnet18(pretrained=True)\n",
    "# 如果出现下载不成功的话，可以手动下载权重，使用model.load_state_dicet方法来装载参数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3005a6e4",
   "metadata": {},
   "source": [
    "### 训练模型的特定层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e3dca7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda\\envs\\project\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "d:\\miniconda\\envs\\project\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# 首先冻结所有参数的梯度计算\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "\n",
    "def set_param_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "feature_extract = True\n",
    "model = models.resnet18(pretrained = True)\n",
    "set_param_requires_grad(model, feature_extract)\n",
    "\n",
    "# 自定义一个输出的全连接层\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(in_features = num_ftrs, out_features=4, bias=True)\n",
    "\n",
    "#之后在训练过程中，model仍会进行梯度回传，但是参数更新则只会发生在fc层。\n",
    "#通过设定参数的requires_grad属性，我们完成了指定训练模型的特定层的目标，这对实现模型微调非常重要。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7521099d",
   "metadata": {},
   "source": [
    "## 关于微调的一些经验\n",
    "### Size一致的情况  \n",
    "+ 新的数据集很少，但是跟源数据集分布相似，且尺寸一致的话，直接微调最终的fc层，冻结其他层。\n",
    "+ 如果数据集数量少且与源数据集分布有差异，可以从神经网络中层开始微调。\n",
    "+ 如果效果都不行的话，就把预训练模型的参数作为初始化重新训练\n",
    "### Size不一致的情况  \n",
    "+ 如果新的数据集尺寸跟原始数据集不一样，可以删掉最终的fc层，加入一些卷积和pool，迫使输出size一致，但这样不好\n",
    "### 对网络进行重新训练  \n",
    "+ 这种情况，可以尝试把中间层的学习率设置为预定的十分之一，输出层学习率设置为正常。\n",
    "\n",
    "## 语音领域微调与CV领域微调的区别\n",
    "+ 语音的底层逻辑差异极大，不同语言有不同的发音特征以及字词，但是语言表达的高级逻辑大致是相似的，因此往往微调浅层。\n",
    "+ CV的底层逻辑差异不大，浅层神经网络往往负责点线面的切割，但高层信息处理的方式差异比较大，一般微调深层。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd52b629",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "# 半精度训练\n",
    "在pytorch中训练模型的过程中，默认的数据存储方式为torch.flat32, 这会使得计算精度更高，同时也导致了更大的算力和显存需求。  \n",
    "因此在一些不要求那么精准的训练中，可以采样***半精度***训练，保留一半的数据长度，即使用float16。  \n",
    "在torch中，我们使用autocast类来进行半精度配置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "441a5efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.cuda.amp import autocast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249775ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在模型定义中，我们可以指定forward为半精度，使用autocast装饰。\n",
    "@autocast()\n",
    "def forward(self,x):\n",
    "    ...\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9131f31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在训练过程中，也可以在数据输入模型之前加入with autocast()上下文就可以了\n",
    "for x in train_loader:\n",
    "    x = x.cuda()\n",
    "    with autocast():\n",
    "        output = model(x)\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0264964",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "# 特别学习：torchaudio，联想librosa、 soundfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b02a2b9",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "torchaudio.io：有关音频的I/O\n",
    "\n",
    "torchaudio.backend：提供了音频处理的后端，包括：sox，soundfile等\n",
    "\n",
    "torchaudio.functional：包含了常用的语音数据处理方法，如：spectrogram，create_fb_matrix等\n",
    "\n",
    "torchaudio.transforms：包含了常用的语音数据预处理方法，如：MFCC，MelScale，AmplitudeToDB等\n",
    "\n",
    "torchaudio.datasets：包含了常用的语音数据集，如：VCTK，LibriSpeech，yesno等\n",
    "\n",
    "torchaudio.models：包含了常用的语音模型，如：Wav2Letter，DeepSpeech等\n",
    "\n",
    "torchaudio.models.decoder：包含了常用的语音解码器，如：GreedyDecoder，BeamSearchDecoder等\n",
    "\n",
    "torchaudio.pipelines：包含了常用的语音处理流水线，如：SpeechRecognitionPipeline，SpeakerRecognitionPipeline等\n",
    "\n",
    "torchaudio.sox_effects：包含了常用的语音处理方法，如：apply_effects_tensor，apply_effects_file等\n",
    "\n",
    "torchaudio.compliance.kaldi：包含了与Kaldi工具兼容的方法，如：load_kaldi_fst，load_kaldi_ark等\n",
    "\n",
    "torchaudio.kalid_io：包含了与Kaldi工具兼容的方法，如：read_vec_flt_scp，read_vec_int_scp等\n",
    "\n",
    "torchaudio.utils：包含了常用的语音工具方法，如：get_audio_backend，set_audio_backend等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11fffbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 直接使用torchaudio自带的YESNO数据集构建dataset\n",
    "import torchaudio\n",
    "import torch\n",
    "\n",
    "yesno_data = torchaudio.datasets.YESNO('.', download=True)\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    yesno_data,\n",
    "    batch_size=1,\n",
    "    shuffle=True,\n",
    "    num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c87c0cac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CMUARCTIC',\n",
       " 'CMUDict',\n",
       " 'COMMONVOICE',\n",
       " 'DR_VCTK',\n",
       " 'FluentSpeechCommands',\n",
       " 'GTZAN',\n",
       " 'IEMOCAP',\n",
       " 'LIBRISPEECH',\n",
       " 'LIBRITTS',\n",
       " 'LJSPEECH',\n",
       " 'LibriLightLimited',\n",
       " 'LibriMix',\n",
       " 'LibriSpeechBiasing',\n",
       " 'MUSDB_HQ',\n",
       " 'QUESST14',\n",
       " 'SPEECHCOMMANDS',\n",
       " 'Snips',\n",
       " 'TEDLIUM',\n",
       " 'VCTK_092',\n",
       " 'VoxCeleb1Identification',\n",
       " 'VoxCeleb1Verification',\n",
       " 'YESNO',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " 'cmuarctic',\n",
       " 'cmudict',\n",
       " 'commonvoice',\n",
       " 'dr_vctk',\n",
       " 'fluentcommands',\n",
       " 'gtzan',\n",
       " 'iemocap',\n",
       " 'librilight_limited',\n",
       " 'librimix',\n",
       " 'librispeech',\n",
       " 'librispeech_biasing',\n",
       " 'libritts',\n",
       " 'ljspeech',\n",
       " 'musdb_hq',\n",
       " 'quesst14',\n",
       " 'snips',\n",
       " 'speechcommands',\n",
       " 'tedlium',\n",
       " 'utils',\n",
       " 'vctk',\n",
       " 'voxceleb1',\n",
       " 'yesno']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torchaudio自带了许多数据集\n",
    "import torchaudio\n",
    "\n",
    "dir(torchaudio.datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9393c76e",
   "metadata": {},
   "source": [
    "### torchaudio的transforms\n",
    "类似于torchvision的transforms继承于torch.nn.Module。下图为其方法图解，包含了一系列从频域到其他域的转变方法。  \n",
    "![transforms包](https://datawhalechina.github.io/thorough-pytorch/_images/torchaudio_feature_extractions.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9854a6",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "# 激活函数\n",
    "如果没有激活函数的话，神经网络不管多复杂，最终的训练结果依然是一个线性函数，等效于只有一个隐藏层的fc网络。激活函数为深度学习网络引入非线性。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e5da62",
   "metadata": {},
   "source": [
    "### Sigmoid函数\n",
    "![](https://i-blog.csdnimg.cn/blog_migrate/2ac04d3695dd9563c3c9a4d357ed8103.jpeg)  \n",
    "sigmoid适合用来做分类任务的输出层，但不太适合用于作为神经网络的激活函数\n",
    "主要缺陷：  \n",
    "+ 当输入数据较大或较小的适合，会导致梯度接近于0。这将导致梯度消失的问题\n",
    "+ 由于simoid函数不过零，这会导致输入的x全为正或全为负时，会导致对权重的导数一直为正或负，导致神经网络训练无法收敛。\n",
    "+ sigmoid中包含幂运算，耗时。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df85157",
   "metadata": {},
   "source": [
    "### tanh函数\n",
    "![](https://i-blog.csdnimg.cn/blog_migrate/73191ced71b237087e4db602ef52037c.jpeg)  \n",
    "tanh函数可以把数据压缩到-1 到 1范围内，可以克服sigmoid函数不过零的缺陷。但同时也会引入sigmoid梯度消失问题。本质上tanh函数是对sigmoid进行线性运算得到的。\n",
    "tanh(x) = 2sigmoid(x) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552a58d0",
   "metadata": {},
   "source": [
    "### ReLU函数\n",
    "![](https://i-blog.csdnimg.cn/blog_migrate/fecf5213b4496be0e63e171c702794d1.jpeg)  \n",
    "优点：  \n",
    "+ 由于正方向导数都是1，因此模型收敛速度比sigmoid和tanh快，同时解决了梯度消失问题\n",
    "+ 前向和反向的计算复杂度低\n",
    "\n",
    "缺点：  \n",
    "+ relu不是以零为中心的，依然可能导致模型不收敛\n",
    "+ 神经元坏死：输出在复数部分，梯度永远为0，参数永远不更新。\n",
    "+ 相对于sigmoid和tanh，relu不会对数据进行压缩"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9800b9fc",
   "metadata": {},
   "source": [
    "### LeakyRelu\n",
    "相比于Relu，复数部分不为零，而是一个带有非常小坡度的直线。避免了relu神经元坏死线性。\n",
    "![](https://i-blog.csdnimg.cn/blog_migrate/1320de0b64bd44540e0d39c926f187a0.jpeg)  \n",
    "但性能未必强于Relu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dedb8a1",
   "metadata": {},
   "source": [
    "# 后记，一些机器学习基本问题和解决方法：\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e543ee4",
   "metadata": {},
   "source": [
    "\n",
    "## 高偏差与高方差\n",
    "- 高偏差的解决方法：\n",
    "    1. 增加隐藏层层数、神经元个数\n",
    "    2. 使用更加复杂的模型\n",
    "    3. 增加模型训练时间\n",
    "- 高方差的解决方法：\n",
    "    1. 使用L1 L2 正则化，缺点，参数难以寻找，计算成本高\n",
    "    2. 引入dropout，随机神经元失活\n",
    "    3. 加入更多的训练数据\n",
    "    4. 训练早停：在训练过程中，参数w会越来越大，早停能防止w过大，实际上接近正则化效果，防止过拟合。早停的缺点是，不能同时降低损失与方差。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44f302a",
   "metadata": {},
   "source": [
    "## 为什么在梯度下降过程中几乎不可能陷入局部最优解\n",
    "当训练参数量非常少，比如二维参数的时候，很多时候会设想作图的多局部最优的目标函数。实际上，假设目标函数在某个方向是凹的或者凸的概率都是0.5，那么在深度学习解决这种解决高维函数的任务中，假设参数维度是20000，那么进入局部最优解的概率仅仅为$2^{-20000}$。事实上我们更容易陷入右边的鞍点！进入鞍点以后，梯度接近0，训练速度会很慢。adam算法能有效解决这个问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bb1fd2",
   "metadata": {},
   "source": [
    "## BatchNorm与LayerNorm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267159f0",
   "metadata": {},
   "source": [
    "### BatchNorm\n",
    "在理解归一化之前，先粗略了解模型训练过程中的***内部协变量偏移***。协变量偏移指的是前一层参数的改变，会导致后层输入分布的改变，从而使得后层的权重变化不稳定，层与层之间的参数更新相互影响。最终训练出来的模型的泛化能力与推理能力也不强。  \n",
    "批归一化解决的就是这个问题，他是在mini-batch层面上对数据进行归一化，计算mini-batch的均值和方差，然后对数据进行归一化。  \n",
    "    ***优点***\n",
    "+ 减少内部协变量偏移，增强各层之间的独立性。\n",
    "+ 加快训练速度。可以使用更大学习率，因为数据都被归一化到一个比较小的范围。\n",
    "+ 减少对初始参数的敏感性，因为每一层的输出最终都会被可学习的缩放和偏移因子处理。且不再需要额外设置bias了，因为最终都会被归一化处理。\n",
    "+ 适用于大batch size的CNN  \n",
    "***缺陷*** \n",
    "+ 对于batch size较小的情况，性能不好\n",
    "+ 在RNN中效果不佳\n",
    "+ 由于推理的时候，batch size可能与训练时不一样，甚至为1，因此必须以指数加权平均的方式，记录训练过程中得到的均值和方差，然后应用到推理中。\n",
    "\n",
    "### layernorm\n",
    "层归一化直接对每个数据样本求均值和方差，不需要额外记录均值与方差。比较适用于RNN的训练。\n",
    "\n",
    "### 为什么归一化可以抑制梯度消失问题\n",
    "+ 对于一些激活函数（如sigmoid或tanh），当输入值过大或过小时，其梯度会趋近于零。BatchNorm通过归一化将输入值保持在激活函数的有效区间内，从而保证了较大的梯度值。\n",
    "+ 由于归一化减少了内部协变量偏移，因此梯度回传会变得更加平稳，较少了梯度消失的现象。\n",
    "+ 减缓了由于参数初始化导致的梯度消失问题。\n",
    "\n",
    "### 为什么会发生梯度消失and梯度爆炸？\n",
    "因为在深层神经网络中，梯度计算是根据复合求导的链式法则来的，每一层神经网络的权重都会参与到梯度回传中，因此会导致梯度指数地减小或者增大，导致梯度消失或梯度爆炸。  \n",
    "+ 导致梯度消失的原因：  \n",
    "    + 如sigmoid和tanh这些带饱和值的激活函数，容易导致梯度消失（归一化）\n",
    "    + 深层神经网络\n",
    "    + 权重初始化，如果初始化值过大，就会导致层的输出过大，导致激活函数饱和。过小会导致层输出过小，导致梯度回传时，梯度很小。  \n",
    "+ 导致梯度爆炸的原因： \n",
    "    + 使用没有饱和特征的激活函数，比如relu\n",
    "    + 深层神经网络\n",
    "    + 权重初始化过大，导致层输出过大，反向传播时导致梯度过大。  \n",
    "    + 学习率过大，导致参数更新不稳定"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
